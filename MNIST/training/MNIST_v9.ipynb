{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MNIST_v9.ipynb","provenance":[],"authorship_tag":"ABX9TyO7vapk0F5kCIaztW/mROUV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"do8w4-cPs_Yk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618958249572,"user_tz":420,"elapsed":574,"user":{"displayName":"Kate Groschner","photoUrl":"","userId":"03462860494048042586"}},"outputId":"3e9aeb80-71b0-46ed-badb-eb6d844a19c1"},"source":["%tensorflow_version 1.x"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6IBVXS6np217","executionInfo":{"status":"ok","timestamp":1618958253850,"user_tz":420,"elapsed":4649,"user":{"displayName":"Kate Groschner","photoUrl":"","userId":"03462860494048042586"}}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n","from tensorflow.keras.models import Sequential, load_model\n","import numpy as np\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","# from keras.utils import to_categorical\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","import h5py\n","from sklearn import utils\n","from tensorflow.keras.backend import clear_session\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from numpy.random import randint"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vghebt4SrHN1","executionInfo":{"status":"ok","timestamp":1618958273081,"user_tz":420,"elapsed":23453,"user":{"displayName":"Kate Groschner","photoUrl":"","userId":"03462860494048042586"}},"outputId":"0d8e69f8-b366-402c-ff59-6a1afb3b7473"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RSGEy2K_r00E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618958275275,"user_tz":420,"elapsed":2150,"user":{"displayName":"Kate Groschner","photoUrl":"","userId":"03462860494048042586"}},"outputId":"c63ee6ec-3165-4b06-8729-2c1418c2afa3"},"source":["data = keras.datasets.mnist.load_data()\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"57oWRVqIrLmM","executionInfo":{"status":"ok","timestamp":1618880367262,"user_tz":420,"elapsed":3062951,"user":{"displayName":"Kate Groschner","photoUrl":"","userId":"03462860494048042586"}},"outputId":"8b4c7904-ac5f-436e-a84f-dd57ad09b63e"},"source":["wrong_frac = 0.00\n","version = 9\n","name_frac = str(wrong_frac).split('.')[-1]\n","if len(name_frac) == 1:\n","    name_frac = name_frac + '0'\n","save_weights = '/content/drive/My Drive/colab/'+ name_frac +'perror_weights_v'+ str(version) + '.h5'\n","save_history = '/content/drive/My Drive/colab/'+ name_frac +'perror_history_v'+ str(version) + '.h5'\n","\n","\n","seven_imgs_train = []\n","seven_labels_train = []\n","for idx,label in enumerate(data[0][1]):\n","    if label == 7:\n","        seven_imgs_train.append(data[0][0][idx])\n","        seven_labels_train.append(label)\n","seven_imgs_train = np.array(seven_imgs_train)\n","seven_labels_train = np.array(seven_labels_train)\n","\n","\n","new_left_images = []\n","new_left_labels = []\n","new_right_images = []\n","new_right_labels = []\n","\n","for img in seven_imgs_train:\n","    new_left_images.append(np.fliplr(img))\n","    new_left_labels.append(0)\n","    new_right_images.append(img)\n","    new_right_labels.append(1)\n","new_left_images = np.array(new_left_images)\n","new_right_images = np.array(new_right_images)\n","\n","\n","X = utils.shuffle(np.concatenate((new_right_images,new_left_images),axis =0),random_state=0)\n","Y = utils.shuffle(np.concatenate((new_right_labels,new_left_labels),axis = 0),random_state=0)\n","\n","train_split = int(len(X)*0.8)\n","val_split = train_split+int(len(X)*0.1)\n","\n","X_train = X[:train_split]\n","X_test = X[train_split:val_split]\n","# X_val = X[val_split:]\n","Y_train = Y[:train_split]\n","Y_test = Y[train_split:val_split]\n","# X_val = X[val_split:]\n","\n","\n","X_train_norm = X_train/X_train.max()\n","X_test_norm = X_test/X_test.max()\n","X_train_norm = np.expand_dims(X_train_norm,axis=3)\n","X_test_norm = np.expand_dims(X_test_norm,axis=3)\n","\n","\n","batch_size = 32\n","seed = 42\n","\n","\n","\n","train_datagen = ImageDataGenerator(\n","        rotation_range = 5,\n","        zoom_range=0.3,\n","        horizontal_flip=False,\n","        vertical_flip = False)\n","\n","test_datagen = ImageDataGenerator(\n","        rotation_range = 5,\n","        zoom_range=0.3,\n","        horizontal_flip=False,\n","        vertical_flip = False)\n","\n","\n","\n","train_generator = train_datagen.flow(X_train_norm, y=Y_train, batch_size=batch_size,seed=seed)\n","val_generator = test_datagen.flow(X_test_norm,y=Y_test,batch_size=batch_size,seed=seed)\n","\n","\n","modelE = keras.models.Sequential()\n","modelE.add(Conv2D(64, (3, 3), input_shape=(28, 28,1)))\n","modelE.add(Activation('relu'))\n","modelE.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\n","modelE.add(Conv2D(64, (3, 3)))\n","modelE.add(Activation('relu'))\n","modelE.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","modelE.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n","modelE.add(Dense(64))\n","modelE.add(Activation('relu'))\n","modelE.add(Dropout(0.5))\n","modelE.add(Dense(1))\n","modelE.add(Activation('sigmoid'))\n","\n","modelE.compile(loss='binary_crossentropy',\n","              optimizer='Adadelta',\n","              metrics=['accuracy'])\n","\n","\n","modelCheckpoint = ModelCheckpoint(save_weights,\n","                                  monitor = 'val_loss',\n","                                  save_best_only = True,\n","                                  mode = 'min',\n","                                  verbose = 2,\n","                                  save_weights_only = True)\n","callbacks_list = [modelCheckpoint]\n","history = modelE.fit_generator(\n","        train_generator,\n","        steps_per_epoch=2870,\n","        epochs=100,\n","        validation_data=val_generator,\n","        validation_steps=358,\n","        verbose = 0,\n","        callbacks=callbacks_list)\n","modelE.save_weights(save_weights)\n","h = h5py.File(save_history,'w')\n","h_keys = history.history.keys()\n","for k in h_keys:\n","    h.create_dataset(k,data=history.history[k])\n","h.close()\n","\n","seven_imgs_test = []\n","for idx,label in enumerate(data[1][1]):\n","    if label == 7:\n","        im_max =data[1][0][idx].max()\n","        seven_imgs_test.append(data[1][0][idx]/im_max)\n","seven_imgs_test = np.array(seven_imgs_test)\n","\n","X_left = np.array([np.fliplr(img) for img in seven_imgs_test])\n","X = np.expand_dims(np.concatenate((seven_imgs_test,X_left),axis=0),axis=3)\n","Y = np.concatenate((np.ones((seven_imgs_test.shape[0],)),np.zeros((X_left.shape[0],))),axis=0)\n","\n","print(modelE.evaluate(X,Y))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["\n","Epoch 00001: val_loss improved from inf to 0.58406, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00002: val_loss improved from 0.58406 to 0.40213, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00003: val_loss improved from 0.40213 to 0.21518, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00004: val_loss improved from 0.21518 to 0.11440, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00005: val_loss improved from 0.11440 to 0.07167, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00006: val_loss improved from 0.07167 to 0.05391, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00007: val_loss improved from 0.05391 to 0.04392, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00008: val_loss improved from 0.04392 to 0.03947, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00009: val_loss improved from 0.03947 to 0.03632, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00010: val_loss improved from 0.03632 to 0.03359, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00011: val_loss improved from 0.03359 to 0.03108, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00012: val_loss did not improve from 0.03108\n","\n","Epoch 00013: val_loss improved from 0.03108 to 0.03018, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00014: val_loss improved from 0.03018 to 0.02999, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00015: val_loss improved from 0.02999 to 0.02877, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00016: val_loss improved from 0.02877 to 0.02755, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00017: val_loss improved from 0.02755 to 0.02674, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00018: val_loss did not improve from 0.02674\n","\n","Epoch 00019: val_loss improved from 0.02674 to 0.02579, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00020: val_loss did not improve from 0.02579\n","\n","Epoch 00021: val_loss did not improve from 0.02579\n","\n","Epoch 00022: val_loss improved from 0.02579 to 0.02469, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00023: val_loss did not improve from 0.02469\n","\n","Epoch 00024: val_loss did not improve from 0.02469\n","\n","Epoch 00025: val_loss improved from 0.02469 to 0.02349, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00026: val_loss did not improve from 0.02349\n","\n","Epoch 00027: val_loss did not improve from 0.02349\n","\n","Epoch 00028: val_loss did not improve from 0.02349\n","\n","Epoch 00029: val_loss improved from 0.02349 to 0.02346, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00030: val_loss improved from 0.02346 to 0.02287, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00031: val_loss did not improve from 0.02287\n","\n","Epoch 00032: val_loss did not improve from 0.02287\n","\n","Epoch 00033: val_loss did not improve from 0.02287\n","\n","Epoch 00034: val_loss improved from 0.02287 to 0.02174, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00035: val_loss did not improve from 0.02174\n","\n","Epoch 00036: val_loss did not improve from 0.02174\n","\n","Epoch 00037: val_loss did not improve from 0.02174\n","\n","Epoch 00038: val_loss improved from 0.02174 to 0.02169, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00039: val_loss improved from 0.02169 to 0.02142, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00040: val_loss improved from 0.02142 to 0.02095, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00041: val_loss did not improve from 0.02095\n","\n","Epoch 00042: val_loss improved from 0.02095 to 0.02013, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00043: val_loss did not improve from 0.02013\n","\n","Epoch 00044: val_loss did not improve from 0.02013\n","\n","Epoch 00045: val_loss did not improve from 0.02013\n","\n","Epoch 00046: val_loss did not improve from 0.02013\n","\n","Epoch 00047: val_loss improved from 0.02013 to 0.01993, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00048: val_loss improved from 0.01993 to 0.01991, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00049: val_loss did not improve from 0.01991\n","\n","Epoch 00050: val_loss did not improve from 0.01991\n","\n","Epoch 00051: val_loss improved from 0.01991 to 0.01911, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00052: val_loss improved from 0.01911 to 0.01888, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00053: val_loss did not improve from 0.01888\n","\n","Epoch 00054: val_loss did not improve from 0.01888\n","\n","Epoch 00055: val_loss improved from 0.01888 to 0.01788, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00056: val_loss did not improve from 0.01788\n","\n","Epoch 00057: val_loss did not improve from 0.01788\n","\n","Epoch 00058: val_loss did not improve from 0.01788\n","\n","Epoch 00059: val_loss did not improve from 0.01788\n","\n","Epoch 00060: val_loss improved from 0.01788 to 0.01783, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00061: val_loss did not improve from 0.01783\n","\n","Epoch 00062: val_loss did not improve from 0.01783\n","\n","Epoch 00063: val_loss did not improve from 0.01783\n","\n","Epoch 00064: val_loss improved from 0.01783 to 0.01731, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00065: val_loss did not improve from 0.01731\n","\n","Epoch 00066: val_loss did not improve from 0.01731\n","\n","Epoch 00067: val_loss improved from 0.01731 to 0.01720, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00068: val_loss did not improve from 0.01720\n","\n","Epoch 00069: val_loss did not improve from 0.01720\n","\n","Epoch 00070: val_loss did not improve from 0.01720\n","\n","Epoch 00071: val_loss improved from 0.01720 to 0.01678, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00072: val_loss did not improve from 0.01678\n","\n","Epoch 00073: val_loss did not improve from 0.01678\n","\n","Epoch 00074: val_loss did not improve from 0.01678\n","\n","Epoch 00075: val_loss did not improve from 0.01678\n","\n","Epoch 00076: val_loss did not improve from 0.01678\n","\n","Epoch 00077: val_loss did not improve from 0.01678\n","\n","Epoch 00078: val_loss improved from 0.01678 to 0.01678, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00079: val_loss did not improve from 0.01678\n","\n","Epoch 00080: val_loss did not improve from 0.01678\n","\n","Epoch 00081: val_loss improved from 0.01678 to 0.01609, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00082: val_loss improved from 0.01609 to 0.01557, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00083: val_loss did not improve from 0.01557\n","\n","Epoch 00084: val_loss did not improve from 0.01557\n","\n","Epoch 00085: val_loss improved from 0.01557 to 0.01545, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00086: val_loss did not improve from 0.01545\n","\n","Epoch 00087: val_loss did not improve from 0.01545\n","\n","Epoch 00088: val_loss did not improve from 0.01545\n","\n","Epoch 00089: val_loss improved from 0.01545 to 0.01469, saving model to /content/drive/My Drive/colab/00perror_weights_v9.h5\n","\n","Epoch 00090: val_loss did not improve from 0.01469\n","\n","Epoch 00091: val_loss did not improve from 0.01469\n","\n","Epoch 00092: val_loss did not improve from 0.01469\n","\n","Epoch 00093: val_loss did not improve from 0.01469\n","\n","Epoch 00094: val_loss did not improve from 0.01469\n","\n","Epoch 00095: val_loss did not improve from 0.01469\n","\n","Epoch 00096: val_loss did not improve from 0.01469\n","\n","Epoch 00097: val_loss did not improve from 0.01469\n","\n","Epoch 00098: val_loss did not improve from 0.01469\n","\n","Epoch 00099: val_loss did not improve from 0.01469\n","\n","Epoch 00100: val_loss did not improve from 0.01469\n","2056/2056 [==============================] - 0s 65us/sample - loss: 0.0062 - acc: 0.9981\n","[0.006155266763859839, 0.9980545]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gIoHHy-zt_WM","executionInfo":{"status":"ok","timestamp":1618963850727,"user_tz":420,"elapsed":2565221,"user":{"displayName":"Kate Groschner","photoUrl":"","userId":"03462860494048042586"}},"outputId":"d65eb1fc-15c8-439a-9823-6b3fa36a3c1a"},"source":["wrong_frac = 0.05\n","version = 9\n","name_frac = str(wrong_frac).split('.')[-1]\n","if len(name_frac) == 1:\n","    name_frac = name_frac + '0'\n","if len(name_frac) == 1:\n","    name_frac = name_frac + '0'\n","save_weights = '/content/drive/My Drive/colab/'+ name_frac +'perror_weights_v'+ str(version) + '.h5'\n","save_history = '/content/drive/My Drive/colab/'+ name_frac +'perror_history_v'+ str(version) + '.h5'\n","\n","\n","seven_imgs_train = []\n","seven_labels_train = []\n","for idx,label in enumerate(data[0][1]):\n","    if label == 7:\n","        seven_imgs_train.append(data[0][0][idx])\n","        seven_labels_train.append(label)\n","seven_imgs_train = np.array(seven_imgs_train)\n","seven_labels_train = np.array(seven_labels_train)\n","\n","\n","new_left_images = []\n","new_left_labels = []\n","new_right_images = []\n","new_right_labels = []\n","\n","for img in seven_imgs_train:\n","    new_left_images.append(np.fliplr(img))\n","    new_left_labels.append(0)\n","    new_right_images.append(img)\n","    new_right_labels.append(1)\n","new_left_images = np.array(new_left_images)\n","new_right_images = np.array(new_right_images)\n","\n","split = int(seven_imgs_train.shape[0]*wrong_frac)\n","\n","for idx in np.arange(0,split):\n","    new_right_images[idx] = np.fliplr(new_right_images[idx])\n","\n","for idx in np.arange(0,split):\n","    new_left_images[idx] = np.fliplr(new_left_images[idx])\n","\n","\n","X = utils.shuffle(np.concatenate((new_right_images,new_left_images),axis =0),random_state=0)\n","Y = utils.shuffle(np.concatenate((new_right_labels,new_left_labels),axis = 0),random_state=0)\n","\n","train_split = int(len(X)*0.8)\n","val_split = train_split+int(len(X)*0.1)\n","\n","X_train = X[:train_split]\n","X_test = X[train_split:val_split]\n","# X_val = X[val_split:]\n","Y_train = Y[:train_split]\n","Y_test = Y[train_split:val_split]\n","# X_val = X[val_split:]\n","\n","X_train_norm = X_train/X_train.max()\n","X_test_norm = X_test/X_test.max()\n","X_train_norm = np.expand_dims(X_train_norm,axis=3)\n","X_test_norm = np.expand_dims(X_test_norm,axis=3)\n","\n","\n","batch_size = 32\n","seed = 42\n","\n","def random_180(img):\n","    turns = randint(0,2)\n","    turns  = turns*2\n","    return np.rot90(img,turns)\n","\n","train_datagen = ImageDataGenerator(\n","        rotation_range = 5,\n","        zoom_range=0.3,\n","        horizontal_flip=False,\n","        vertical_flip = False)\n","\n","test_datagen = ImageDataGenerator(\n","        rotation_range = 5,\n","        zoom_range=0.3,\n","        horizontal_flip=False,\n","        vertical_flip = False)\n","\n","\n","\n","train_generator = train_datagen.flow(X_train_norm, y=Y_train, batch_size=batch_size,seed=seed)\n","val_generator = test_datagen.flow(X_test_norm,y=Y_test,batch_size=batch_size,seed=seed)\n","\n","\n","modelE = keras.models.Sequential()\n","modelE.add(Conv2D(64, (3, 3), input_shape=(28, 28,1)))\n","modelE.add(Activation('relu'))\n","modelE.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\n","modelE.add(Conv2D(64, (3, 3)))\n","modelE.add(Activation('relu'))\n","modelE.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","modelE.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n","modelE.add(Dense(64))\n","modelE.add(Activation('relu'))\n","modelE.add(Dropout(0.5))\n","modelE.add(Dense(1))\n","modelE.add(Activation('sigmoid'))\n","\n","modelE.compile(loss='binary_crossentropy',\n","              optimizer='Adadelta',\n","              metrics=['accuracy'])\n","\n","\n","modelCheckpoint = ModelCheckpoint(save_weights,\n","                                  monitor = 'val_loss',\n","                                  save_best_only = True,\n","                                  mode = 'min',\n","                                  verbose = 2,\n","                                  save_weights_only = True)\n","callbacks_list = [modelCheckpoint]\n","history = modelE.fit_generator(\n","        train_generator,\n","        steps_per_epoch=2870,\n","        epochs=100,\n","        validation_data=val_generator,\n","        validation_steps=358,\n","        verbose = 0,\n","        callbacks=callbacks_list)\n","modelE.save_weights(save_weights)\n","h = h5py.File(save_history,'w')\n","h_keys = history.history.keys()\n","for k in h_keys:\n","    h.create_dataset(k,data=history.history[k])\n","h.close()\n","\n","print(modelE.evaluate(X_test_norm,Y_test))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["\n","Epoch 00001: val_loss improved from inf to 0.58278, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00002: val_loss improved from 0.58278 to 0.43880, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00003: val_loss improved from 0.43880 to 0.33524, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00004: val_loss improved from 0.33524 to 0.28937, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00005: val_loss improved from 0.28937 to 0.27768, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00006: val_loss improved from 0.27768 to 0.27681, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00007: val_loss improved from 0.27681 to 0.27279, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00008: val_loss improved from 0.27279 to 0.27052, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00009: val_loss did not improve from 0.27052\n","\n","Epoch 00010: val_loss did not improve from 0.27052\n","\n","Epoch 00011: val_loss improved from 0.27052 to 0.26591, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00012: val_loss did not improve from 0.26591\n","\n","Epoch 00013: val_loss improved from 0.26591 to 0.25900, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00014: val_loss did not improve from 0.25900\n","\n","Epoch 00015: val_loss did not improve from 0.25900\n","\n","Epoch 00016: val_loss did not improve from 0.25900\n","\n","Epoch 00017: val_loss did not improve from 0.25900\n","\n","Epoch 00018: val_loss did not improve from 0.25900\n","\n","Epoch 00019: val_loss did not improve from 0.25900\n","\n","Epoch 00020: val_loss improved from 0.25900 to 0.25793, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00021: val_loss did not improve from 0.25793\n","\n","Epoch 00022: val_loss did not improve from 0.25793\n","\n","Epoch 00023: val_loss improved from 0.25793 to 0.25722, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00024: val_loss improved from 0.25722 to 0.25596, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00025: val_loss did not improve from 0.25596\n","\n","Epoch 00026: val_loss did not improve from 0.25596\n","\n","Epoch 00027: val_loss did not improve from 0.25596\n","\n","Epoch 00028: val_loss improved from 0.25596 to 0.25350, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00029: val_loss did not improve from 0.25350\n","\n","Epoch 00030: val_loss improved from 0.25350 to 0.25157, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00031: val_loss did not improve from 0.25157\n","\n","Epoch 00032: val_loss did not improve from 0.25157\n","\n","Epoch 00033: val_loss did not improve from 0.25157\n","\n","Epoch 00034: val_loss improved from 0.25157 to 0.24802, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00035: val_loss did not improve from 0.24802\n","\n","Epoch 00036: val_loss did not improve from 0.24802\n","\n","Epoch 00037: val_loss did not improve from 0.24802\n","\n","Epoch 00038: val_loss did not improve from 0.24802\n","\n","Epoch 00039: val_loss did not improve from 0.24802\n","\n","Epoch 00040: val_loss did not improve from 0.24802\n","\n","Epoch 00041: val_loss did not improve from 0.24802\n","\n","Epoch 00042: val_loss did not improve from 0.24802\n","\n","Epoch 00043: val_loss did not improve from 0.24802\n","\n","Epoch 00044: val_loss improved from 0.24802 to 0.24783, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00045: val_loss improved from 0.24783 to 0.24732, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00046: val_loss did not improve from 0.24732\n","\n","Epoch 00047: val_loss did not improve from 0.24732\n","\n","Epoch 00048: val_loss did not improve from 0.24732\n","\n","Epoch 00049: val_loss improved from 0.24732 to 0.24464, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00050: val_loss did not improve from 0.24464\n","\n","Epoch 00051: val_loss did not improve from 0.24464\n","\n","Epoch 00052: val_loss did not improve from 0.24464\n","\n","Epoch 00053: val_loss did not improve from 0.24464\n","\n","Epoch 00054: val_loss did not improve from 0.24464\n","\n","Epoch 00055: val_loss did not improve from 0.24464\n","\n","Epoch 00056: val_loss did not improve from 0.24464\n","\n","Epoch 00057: val_loss did not improve from 0.24464\n","\n","Epoch 00058: val_loss did not improve from 0.24464\n","\n","Epoch 00059: val_loss did not improve from 0.24464\n","\n","Epoch 00060: val_loss improved from 0.24464 to 0.24438, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00061: val_loss did not improve from 0.24438\n","\n","Epoch 00062: val_loss did not improve from 0.24438\n","\n","Epoch 00063: val_loss did not improve from 0.24438\n","\n","Epoch 00064: val_loss improved from 0.24438 to 0.24248, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00065: val_loss did not improve from 0.24248\n","\n","Epoch 00066: val_loss did not improve from 0.24248\n","\n","Epoch 00067: val_loss did not improve from 0.24248\n","\n","Epoch 00068: val_loss did not improve from 0.24248\n","\n","Epoch 00069: val_loss did not improve from 0.24248\n","\n","Epoch 00070: val_loss improved from 0.24248 to 0.24084, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00071: val_loss did not improve from 0.24084\n","\n","Epoch 00072: val_loss did not improve from 0.24084\n","\n","Epoch 00073: val_loss did not improve from 0.24084\n","\n","Epoch 00074: val_loss did not improve from 0.24084\n","\n","Epoch 00075: val_loss improved from 0.24084 to 0.23915, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00076: val_loss did not improve from 0.23915\n","\n","Epoch 00077: val_loss did not improve from 0.23915\n","\n","Epoch 00078: val_loss did not improve from 0.23915\n","\n","Epoch 00079: val_loss did not improve from 0.23915\n","\n","Epoch 00080: val_loss did not improve from 0.23915\n","\n","Epoch 00081: val_loss did not improve from 0.23915\n","\n","Epoch 00082: val_loss did not improve from 0.23915\n","\n","Epoch 00083: val_loss did not improve from 0.23915\n","\n","Epoch 00084: val_loss did not improve from 0.23915\n","\n","Epoch 00085: val_loss did not improve from 0.23915\n","\n","Epoch 00086: val_loss did not improve from 0.23915\n","\n","Epoch 00087: val_loss did not improve from 0.23915\n","\n","Epoch 00088: val_loss did not improve from 0.23915\n","\n","Epoch 00089: val_loss did not improve from 0.23915\n","\n","Epoch 00090: val_loss did not improve from 0.23915\n","\n","Epoch 00091: val_loss improved from 0.23915 to 0.23669, saving model to /content/drive/My Drive/colab/05perror_weights_v9.h5\n","\n","Epoch 00092: val_loss did not improve from 0.23669\n","\n","Epoch 00093: val_loss did not improve from 0.23669\n","\n","Epoch 00094: val_loss did not improve from 0.23669\n","\n","Epoch 00095: val_loss did not improve from 0.23669\n","\n","Epoch 00096: val_loss did not improve from 0.23669\n","\n","Epoch 00097: val_loss did not improve from 0.23669\n","\n","Epoch 00098: val_loss did not improve from 0.23669\n","\n","Epoch 00099: val_loss did not improve from 0.23669\n","\n","Epoch 00100: val_loss did not improve from 0.23669\n","1253/1253 [==============================] - 0s 52us/sample - loss: 0.2447 - acc: 0.9385\n","[0.24465105363300868, 0.9385475]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EB9r5jRHtlI9","executionInfo":{"status":"ok","timestamp":1618966423587,"user_tz":420,"elapsed":2572853,"user":{"displayName":"Kate Groschner","photoUrl":"","userId":"03462860494048042586"}},"outputId":"046883bb-e2e6-4dcd-c224-d71b91c3a841"},"source":["wrong_frac = 0.1\n","version = 9\n","name_frac = str(wrong_frac).split('.')[-1]\n","if len(name_frac) == 1:\n","    name_frac = name_frac + '0'\n","if len(name_frac) == 1:\n","    name_frac = name_frac + '0'\n","save_weights = '/content/drive/My Drive/colab/'+ name_frac +'perror_weights_v'+ str(version) + '.h5'\n","save_history = '/content/drive/My Drive/colab/'+ name_frac +'perror_history_v'+ str(version) + '.h5'\n","\n","\n","seven_imgs_train = []\n","seven_labels_train = []\n","for idx,label in enumerate(data[0][1]):\n","    if label == 7:\n","        seven_imgs_train.append(data[0][0][idx])\n","        seven_labels_train.append(label)\n","seven_imgs_train = np.array(seven_imgs_train)\n","seven_labels_train = np.array(seven_labels_train)\n","\n","\n","new_left_images = []\n","new_left_labels = []\n","new_right_images = []\n","new_right_labels = []\n","\n","for img in seven_imgs_train:\n","    new_left_images.append(np.fliplr(img))\n","    new_left_labels.append(0)\n","    new_right_images.append(img)\n","    new_right_labels.append(1)\n","new_left_images = np.array(new_left_images)\n","new_right_images = np.array(new_right_images)\n","\n","split = int(seven_imgs_train.shape[0]*wrong_frac)\n","\n","for idx in np.arange(0,split):\n","    new_right_images[idx] = np.fliplr(new_right_images[idx])\n","\n","for idx in np.arange(0,split):\n","    new_left_images[idx] = np.fliplr(new_left_images[idx])\n","\n","\n","X = utils.shuffle(np.concatenate((new_right_images,new_left_images),axis =0),random_state=0)\n","Y = utils.shuffle(np.concatenate((new_right_labels,new_left_labels),axis = 0),random_state=0)\n","\n","train_split = int(len(X)*0.8)\n","val_split = train_split+int(len(X)*0.1)\n","\n","X_train = X[:train_split]\n","X_test = X[train_split:val_split]\n","# X_val = X[val_split:]\n","Y_train = Y[:train_split]\n","Y_test = Y[train_split:val_split]\n","# X_val = X[val_split:]\n","\n","X_train_norm = X_train/X_train.max()\n","X_test_norm = X_test/X_test.max()\n","X_train_norm = np.expand_dims(X_train_norm,axis=3)\n","X_test_norm = np.expand_dims(X_test_norm,axis=3)\n","\n","\n","batch_size = 32\n","seed = 42\n","\n","def random_180(img):\n","    turns = randint(0,2)\n","    turns  = turns*2\n","    return np.rot90(img,turns)\n","\n","train_datagen = ImageDataGenerator(\n","        rotation_range = 5,\n","        zoom_range=0.3,\n","        horizontal_flip=False,\n","        vertical_flip = False)\n","\n","test_datagen = ImageDataGenerator(\n","        rotation_range = 5,\n","        zoom_range=0.3,\n","        horizontal_flip=False,\n","        vertical_flip = False)\n","\n","\n","\n","train_generator = train_datagen.flow(X_train_norm, y=Y_train, batch_size=batch_size,seed=seed)\n","val_generator = test_datagen.flow(X_test_norm,y=Y_test,batch_size=batch_size,seed=seed)\n","\n","\n","modelE = keras.models.Sequential()\n","modelE.add(Conv2D(64, (3, 3), input_shape=(28, 28,1)))\n","modelE.add(Activation('relu'))\n","modelE.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\n","modelE.add(Conv2D(64, (3, 3)))\n","modelE.add(Activation('relu'))\n","modelE.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","modelE.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n","modelE.add(Dense(64))\n","modelE.add(Activation('relu'))\n","modelE.add(Dropout(0.5))\n","modelE.add(Dense(1))\n","modelE.add(Activation('sigmoid'))\n","\n","modelE.compile(loss='binary_crossentropy',\n","              optimizer='Adadelta',\n","              metrics=['accuracy'])\n","\n","\n","modelCheckpoint = ModelCheckpoint(save_weights,\n","                                  monitor = 'val_loss',\n","                                  save_best_only = True,\n","                                  mode = 'min',\n","                                  verbose = 2,\n","                                  save_weights_only = True)\n","callbacks_list = [modelCheckpoint]\n","history = modelE.fit_generator(\n","        train_generator,\n","        steps_per_epoch=2870,\n","        epochs=100,\n","        validation_data=val_generator,\n","        validation_steps=358,\n","        verbose = 0,\n","        callbacks=callbacks_list)\n","modelE.save_weights(save_weights)\n","h = h5py.File(save_history,'w')\n","h_keys = history.history.keys()\n","for k in h_keys:\n","    h.create_dataset(k,data=history.history[k])\n","h.close()\n","\n","print(modelE.evaluate(X_test_norm,Y_test))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["\n","Epoch 00001: val_loss improved from inf to 0.62298, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00002: val_loss improved from 0.62298 to 0.53581, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00003: val_loss improved from 0.53581 to 0.45236, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00004: val_loss improved from 0.45236 to 0.40604, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00005: val_loss improved from 0.40604 to 0.39003, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00006: val_loss improved from 0.39003 to 0.38891, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00007: val_loss improved from 0.38891 to 0.38416, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00008: val_loss improved from 0.38416 to 0.38115, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00009: val_loss improved from 0.38115 to 0.38009, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00010: val_loss did not improve from 0.38009\n","\n","Epoch 00011: val_loss improved from 0.38009 to 0.37874, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00012: val_loss improved from 0.37874 to 0.37847, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00013: val_loss improved from 0.37847 to 0.37283, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00014: val_loss improved from 0.37283 to 0.37180, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00015: val_loss did not improve from 0.37180\n","\n","Epoch 00016: val_loss improved from 0.37180 to 0.37131, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00017: val_loss did not improve from 0.37131\n","\n","Epoch 00018: val_loss improved from 0.37131 to 0.37031, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00019: val_loss improved from 0.37031 to 0.37014, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00020: val_loss did not improve from 0.37014\n","\n","Epoch 00021: val_loss did not improve from 0.37014\n","\n","Epoch 00022: val_loss did not improve from 0.37014\n","\n","Epoch 00023: val_loss improved from 0.37014 to 0.36849, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00024: val_loss did not improve from 0.36849\n","\n","Epoch 00025: val_loss did not improve from 0.36849\n","\n","Epoch 00026: val_loss improved from 0.36849 to 0.36595, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00027: val_loss did not improve from 0.36595\n","\n","Epoch 00028: val_loss did not improve from 0.36595\n","\n","Epoch 00029: val_loss did not improve from 0.36595\n","\n","Epoch 00030: val_loss improved from 0.36595 to 0.36298, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00031: val_loss did not improve from 0.36298\n","\n","Epoch 00032: val_loss improved from 0.36298 to 0.36201, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00033: val_loss did not improve from 0.36201\n","\n","Epoch 00034: val_loss did not improve from 0.36201\n","\n","Epoch 00035: val_loss did not improve from 0.36201\n","\n","Epoch 00036: val_loss did not improve from 0.36201\n","\n","Epoch 00037: val_loss did not improve from 0.36201\n","\n","Epoch 00038: val_loss did not improve from 0.36201\n","\n","Epoch 00039: val_loss did not improve from 0.36201\n","\n","Epoch 00040: val_loss did not improve from 0.36201\n","\n","Epoch 00041: val_loss improved from 0.36201 to 0.36091, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00042: val_loss did not improve from 0.36091\n","\n","Epoch 00043: val_loss did not improve from 0.36091\n","\n","Epoch 00044: val_loss improved from 0.36091 to 0.36078, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00045: val_loss did not improve from 0.36078\n","\n","Epoch 00046: val_loss did not improve from 0.36078\n","\n","Epoch 00047: val_loss did not improve from 0.36078\n","\n","Epoch 00048: val_loss improved from 0.36078 to 0.35954, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00049: val_loss improved from 0.35954 to 0.35612, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00050: val_loss did not improve from 0.35612\n","\n","Epoch 00051: val_loss did not improve from 0.35612\n","\n","Epoch 00052: val_loss did not improve from 0.35612\n","\n","Epoch 00053: val_loss did not improve from 0.35612\n","\n","Epoch 00054: val_loss did not improve from 0.35612\n","\n","Epoch 00055: val_loss did not improve from 0.35612\n","\n","Epoch 00056: val_loss did not improve from 0.35612\n","\n","Epoch 00057: val_loss did not improve from 0.35612\n","\n","Epoch 00058: val_loss did not improve from 0.35612\n","\n","Epoch 00059: val_loss did not improve from 0.35612\n","\n","Epoch 00060: val_loss did not improve from 0.35612\n","\n","Epoch 00061: val_loss did not improve from 0.35612\n","\n","Epoch 00062: val_loss did not improve from 0.35612\n","\n","Epoch 00063: val_loss did not improve from 0.35612\n","\n","Epoch 00064: val_loss did not improve from 0.35612\n","\n","Epoch 00065: val_loss did not improve from 0.35612\n","\n","Epoch 00066: val_loss did not improve from 0.35612\n","\n","Epoch 00067: val_loss did not improve from 0.35612\n","\n","Epoch 00068: val_loss did not improve from 0.35612\n","\n","Epoch 00069: val_loss did not improve from 0.35612\n","\n","Epoch 00070: val_loss improved from 0.35612 to 0.35446, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00071: val_loss did not improve from 0.35446\n","\n","Epoch 00072: val_loss did not improve from 0.35446\n","\n","Epoch 00073: val_loss did not improve from 0.35446\n","\n","Epoch 00074: val_loss did not improve from 0.35446\n","\n","Epoch 00075: val_loss improved from 0.35446 to 0.35402, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00076: val_loss did not improve from 0.35402\n","\n","Epoch 00077: val_loss did not improve from 0.35402\n","\n","Epoch 00078: val_loss did not improve from 0.35402\n","\n","Epoch 00079: val_loss did not improve from 0.35402\n","\n","Epoch 00080: val_loss did not improve from 0.35402\n","\n","Epoch 00081: val_loss did not improve from 0.35402\n","\n","Epoch 00082: val_loss did not improve from 0.35402\n","\n","Epoch 00083: val_loss did not improve from 0.35402\n","\n","Epoch 00084: val_loss did not improve from 0.35402\n","\n","Epoch 00085: val_loss did not improve from 0.35402\n","\n","Epoch 00086: val_loss did not improve from 0.35402\n","\n","Epoch 00087: val_loss did not improve from 0.35402\n","\n","Epoch 00088: val_loss did not improve from 0.35402\n","\n","Epoch 00089: val_loss did not improve from 0.35402\n","\n","Epoch 00090: val_loss did not improve from 0.35402\n","\n","Epoch 00091: val_loss improved from 0.35402 to 0.35222, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00092: val_loss did not improve from 0.35222\n","\n","Epoch 00093: val_loss improved from 0.35222 to 0.35126, saving model to /content/drive/My Drive/colab/10perror_weights_v9.h5\n","\n","Epoch 00094: val_loss did not improve from 0.35126\n","\n","Epoch 00095: val_loss did not improve from 0.35126\n","\n","Epoch 00096: val_loss did not improve from 0.35126\n","\n","Epoch 00097: val_loss did not improve from 0.35126\n","\n","Epoch 00098: val_loss did not improve from 0.35126\n","\n","Epoch 00099: val_loss did not improve from 0.35126\n","\n","Epoch 00100: val_loss did not improve from 0.35126\n","1253/1253 [==============================] - 0s 59us/sample - loss: 0.3569 - acc: 0.8883\n","[0.35694534637789105, 0.8882682]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e7anldB8tm1U","executionInfo":{"status":"ok","timestamp":1618968997197,"user_tz":420,"elapsed":5146456,"user":{"displayName":"Kate Groschner","photoUrl":"","userId":"03462860494048042586"}},"outputId":"b4aa7f77-f3a9-4508-d2d7-31aa5475cc09"},"source":["wrong_frac = 0.2\n","version = 9\n","name_frac = str(wrong_frac).split('.')[-1]\n","if len(name_frac) == 1:\n","    name_frac = name_frac + '0'\n","if len(name_frac) == 1:\n","    name_frac = name_frac + '0'\n","save_weights = '/content/drive/My Drive/colab/'+ name_frac +'perror_weights_v'+ str(version) + '.h5'\n","save_history = '/content/drive/My Drive/colab/'+ name_frac +'perror_history_v'+ str(version) + '.h5'\n","\n","\n","seven_imgs_train = []\n","seven_labels_train = []\n","for idx,label in enumerate(data[0][1]):\n","    if label == 7:\n","        seven_imgs_train.append(data[0][0][idx])\n","        seven_labels_train.append(label)\n","seven_imgs_train = np.array(seven_imgs_train)\n","seven_labels_train = np.array(seven_labels_train)\n","\n","\n","new_left_images = []\n","new_left_labels = []\n","new_right_images = []\n","new_right_labels = []\n","\n","for img in seven_imgs_train:\n","    new_left_images.append(np.fliplr(img))\n","    new_left_labels.append(0)\n","    new_right_images.append(img)\n","    new_right_labels.append(1)\n","new_left_images = np.array(new_left_images)\n","new_right_images = np.array(new_right_images)\n","\n","split = int(seven_imgs_train.shape[0]*wrong_frac)\n","\n","for idx in np.arange(0,split):\n","    new_right_images[idx] = np.fliplr(new_right_images[idx])\n","\n","for idx in np.arange(0,split):\n","    new_left_images[idx] = np.fliplr(new_left_images[idx])\n","\n","\n","X = utils.shuffle(np.concatenate((new_right_images,new_left_images),axis =0),random_state=0)\n","Y = utils.shuffle(np.concatenate((new_right_labels,new_left_labels),axis = 0),random_state=0)\n","\n","train_split = int(len(X)*0.8)\n","val_split = train_split+int(len(X)*0.1)\n","\n","X_train = X[:train_split]\n","X_test = X[train_split:val_split]\n","# X_val = X[val_split:]\n","Y_train = Y[:train_split]\n","Y_test = Y[train_split:val_split]\n","# X_val = X[val_split:]\n","\n","X_train_norm = X_train/X_train.max()\n","X_test_norm = X_test/X_test.max()\n","X_train_norm = np.expand_dims(X_train_norm,axis=3)\n","X_test_norm = np.expand_dims(X_test_norm,axis=3)\n","\n","\n","batch_size = 32\n","seed = 42\n","\n","def random_180(img):\n","    turns = randint(0,2)\n","    turns  = turns*2\n","    return np.rot90(img,turns)\n","\n","train_datagen = ImageDataGenerator(\n","        rotation_range = 5,\n","        zoom_range=0.3,\n","        horizontal_flip=False,\n","        vertical_flip = False)\n","\n","test_datagen = ImageDataGenerator(\n","        rotation_range = 5,\n","        zoom_range=0.3,\n","        horizontal_flip=False,\n","        vertical_flip = False)\n","\n","\n","\n","train_generator = train_datagen.flow(X_train_norm, y=Y_train, batch_size=batch_size,seed=seed)\n","val_generator = test_datagen.flow(X_test_norm,y=Y_test,batch_size=batch_size,seed=seed)\n","\n","\n","modelE = keras.models.Sequential()\n","modelE.add(Conv2D(64, (3, 3), input_shape=(28, 28,1)))\n","modelE.add(Activation('relu'))\n","modelE.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\n","modelE.add(Conv2D(64, (3, 3)))\n","modelE.add(Activation('relu'))\n","modelE.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","modelE.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n","modelE.add(Dense(64))\n","modelE.add(Activation('relu'))\n","modelE.add(Dropout(0.5))\n","modelE.add(Dense(1))\n","modelE.add(Activation('sigmoid'))\n","\n","modelE.compile(loss='binary_crossentropy',\n","              optimizer='Adadelta',\n","              metrics=['accuracy'])\n","\n","\n","modelCheckpoint = ModelCheckpoint(save_weights,\n","                                  monitor = 'val_loss',\n","                                  save_best_only = True,\n","                                  mode = 'min',\n","                                  verbose = 2,\n","                                  save_weights_only = True)\n","callbacks_list = [modelCheckpoint]\n","history = modelE.fit_generator(\n","        train_generator,\n","        steps_per_epoch=2870,\n","        epochs=100,\n","        validation_data=val_generator,\n","        validation_steps=358,\n","        verbose = 0,\n","        callbacks=callbacks_list)\n","modelE.save_weights(save_weights)\n","h = h5py.File(save_history,'w')\n","h_keys = history.history.keys()\n","for k in h_keys:\n","    h.create_dataset(k,data=history.history[k])\n","h.close()\n","\n","print(modelE.evaluate(X_test_norm,Y_test))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["\n","Epoch 00001: val_loss improved from inf to 0.65791, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00002: val_loss improved from 0.65791 to 0.62045, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00003: val_loss improved from 0.62045 to 0.58465, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00004: val_loss improved from 0.58465 to 0.55650, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00005: val_loss improved from 0.55650 to 0.54250, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00006: val_loss improved from 0.54250 to 0.54006, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00007: val_loss improved from 0.54006 to 0.53646, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00008: val_loss improved from 0.53646 to 0.53127, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00009: val_loss did not improve from 0.53127\n","\n","Epoch 00010: val_loss did not improve from 0.53127\n","\n","Epoch 00011: val_loss did not improve from 0.53127\n","\n","Epoch 00012: val_loss improved from 0.53127 to 0.53124, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00013: val_loss improved from 0.53124 to 0.52791, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00014: val_loss did not improve from 0.52791\n","\n","Epoch 00015: val_loss did not improve from 0.52791\n","\n","Epoch 00016: val_loss improved from 0.52791 to 0.52696, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00017: val_loss did not improve from 0.52696\n","\n","Epoch 00018: val_loss improved from 0.52696 to 0.52510, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00019: val_loss did not improve from 0.52510\n","\n","Epoch 00020: val_loss did not improve from 0.52510\n","\n","Epoch 00021: val_loss did not improve from 0.52510\n","\n","Epoch 00022: val_loss did not improve from 0.52510\n","\n","Epoch 00023: val_loss improved from 0.52510 to 0.52422, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00024: val_loss did not improve from 0.52422\n","\n","Epoch 00025: val_loss did not improve from 0.52422\n","\n","Epoch 00026: val_loss did not improve from 0.52422\n","\n","Epoch 00027: val_loss did not improve from 0.52422\n","\n","Epoch 00028: val_loss improved from 0.52422 to 0.52337, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00029: val_loss did not improve from 0.52337\n","\n","Epoch 00030: val_loss improved from 0.52337 to 0.52131, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00031: val_loss did not improve from 0.52131\n","\n","Epoch 00032: val_loss did not improve from 0.52131\n","\n","Epoch 00033: val_loss did not improve from 0.52131\n","\n","Epoch 00034: val_loss did not improve from 0.52131\n","\n","Epoch 00035: val_loss did not improve from 0.52131\n","\n","Epoch 00036: val_loss did not improve from 0.52131\n","\n","Epoch 00037: val_loss did not improve from 0.52131\n","\n","Epoch 00038: val_loss did not improve from 0.52131\n","\n","Epoch 00039: val_loss did not improve from 0.52131\n","\n","Epoch 00040: val_loss improved from 0.52131 to 0.52104, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00041: val_loss improved from 0.52104 to 0.52090, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00042: val_loss did not improve from 0.52090\n","\n","Epoch 00043: val_loss did not improve from 0.52090\n","\n","Epoch 00044: val_loss improved from 0.52090 to 0.52000, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00045: val_loss did not improve from 0.52000\n","\n","Epoch 00046: val_loss did not improve from 0.52000\n","\n","Epoch 00047: val_loss did not improve from 0.52000\n","\n","Epoch 00048: val_loss did not improve from 0.52000\n","\n","Epoch 00049: val_loss improved from 0.52000 to 0.51798, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00050: val_loss did not improve from 0.51798\n","\n","Epoch 00051: val_loss did not improve from 0.51798\n","\n","Epoch 00052: val_loss did not improve from 0.51798\n","\n","Epoch 00053: val_loss did not improve from 0.51798\n","\n","Epoch 00054: val_loss did not improve from 0.51798\n","\n","Epoch 00055: val_loss improved from 0.51798 to 0.51752, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00056: val_loss did not improve from 0.51752\n","\n","Epoch 00057: val_loss did not improve from 0.51752\n","\n","Epoch 00058: val_loss did not improve from 0.51752\n","\n","Epoch 00059: val_loss did not improve from 0.51752\n","\n","Epoch 00060: val_loss did not improve from 0.51752\n","\n","Epoch 00061: val_loss did not improve from 0.51752\n","\n","Epoch 00062: val_loss did not improve from 0.51752\n","\n","Epoch 00063: val_loss did not improve from 0.51752\n","\n","Epoch 00064: val_loss did not improve from 0.51752\n","\n","Epoch 00065: val_loss did not improve from 0.51752\n","\n","Epoch 00066: val_loss did not improve from 0.51752\n","\n","Epoch 00067: val_loss did not improve from 0.51752\n","\n","Epoch 00068: val_loss improved from 0.51752 to 0.51678, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00069: val_loss did not improve from 0.51678\n","\n","Epoch 00070: val_loss did not improve from 0.51678\n","\n","Epoch 00071: val_loss did not improve from 0.51678\n","\n","Epoch 00072: val_loss did not improve from 0.51678\n","\n","Epoch 00073: val_loss did not improve from 0.51678\n","\n","Epoch 00074: val_loss did not improve from 0.51678\n","\n","Epoch 00075: val_loss improved from 0.51678 to 0.51602, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00076: val_loss did not improve from 0.51602\n","\n","Epoch 00077: val_loss did not improve from 0.51602\n","\n","Epoch 00078: val_loss did not improve from 0.51602\n","\n","Epoch 00079: val_loss did not improve from 0.51602\n","\n","Epoch 00080: val_loss did not improve from 0.51602\n","\n","Epoch 00081: val_loss did not improve from 0.51602\n","\n","Epoch 00082: val_loss did not improve from 0.51602\n","\n","Epoch 00083: val_loss did not improve from 0.51602\n","\n","Epoch 00084: val_loss did not improve from 0.51602\n","\n","Epoch 00085: val_loss did not improve from 0.51602\n","\n","Epoch 00086: val_loss did not improve from 0.51602\n","\n","Epoch 00087: val_loss did not improve from 0.51602\n","\n","Epoch 00088: val_loss did not improve from 0.51602\n","\n","Epoch 00089: val_loss did not improve from 0.51602\n","\n","Epoch 00090: val_loss did not improve from 0.51602\n","\n","Epoch 00091: val_loss improved from 0.51602 to 0.51594, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00092: val_loss did not improve from 0.51594\n","\n","Epoch 00093: val_loss improved from 0.51594 to 0.51350, saving model to /content/drive/My Drive/colab/20perror_weights_v9.h5\n","\n","Epoch 00094: val_loss did not improve from 0.51350\n","\n","Epoch 00095: val_loss did not improve from 0.51350\n","\n","Epoch 00096: val_loss did not improve from 0.51350\n","\n","Epoch 00097: val_loss did not improve from 0.51350\n","\n","Epoch 00098: val_loss did not improve from 0.51350\n","\n","Epoch 00099: val_loss did not improve from 0.51350\n","\n","Epoch 00100: val_loss did not improve from 0.51350\n","1253/1253 [==============================] - 0s 57us/sample - loss: 0.5174 - acc: 0.7917\n","[0.5173797075594319, 0.79169995]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ukxF1Hv3tpAD","executionInfo":{"status":"ok","timestamp":1618971574763,"user_tz":420,"elapsed":7724017,"user":{"displayName":"Kate Groschner","photoUrl":"","userId":"03462860494048042586"}},"outputId":"89cfb20f-40ea-475f-fecc-8916f1b07c57"},"source":["wrong_frac = 0.3\n","version = 9\n","name_frac = str(wrong_frac).split('.')[-1]\n","if len(name_frac) == 1:\n","    name_frac = name_frac + '0'\n","if len(name_frac) == 1:\n","    name_frac = name_frac + '0'\n","save_weights = '/content/drive/My Drive/colab/'+ name_frac +'perror_weights_v'+ str(version) + '.h5'\n","save_history = '/content/drive/My Drive/colab/'+ name_frac +'perror_history_v'+ str(version) + '.h5'\n","\n","\n","seven_imgs_train = []\n","seven_labels_train = []\n","for idx,label in enumerate(data[0][1]):\n","    if label == 7:\n","        seven_imgs_train.append(data[0][0][idx])\n","        seven_labels_train.append(label)\n","seven_imgs_train = np.array(seven_imgs_train)\n","seven_labels_train = np.array(seven_labels_train)\n","\n","\n","new_left_images = []\n","new_left_labels = []\n","new_right_images = []\n","new_right_labels = []\n","\n","for img in seven_imgs_train:\n","    new_left_images.append(np.fliplr(img))\n","    new_left_labels.append(0)\n","    new_right_images.append(img)\n","    new_right_labels.append(1)\n","new_left_images = np.array(new_left_images)\n","new_right_images = np.array(new_right_images)\n","\n","split = int(seven_imgs_train.shape[0]*wrong_frac)\n","\n","for idx in np.arange(0,split):\n","    new_right_images[idx] = np.fliplr(new_right_images[idx])\n","\n","for idx in np.arange(0,split):\n","    new_left_images[idx] = np.fliplr(new_left_images[idx])\n","\n","\n","X = utils.shuffle(np.concatenate((new_right_images,new_left_images),axis =0),random_state=0)\n","Y = utils.shuffle(np.concatenate((new_right_labels,new_left_labels),axis = 0),random_state=0)\n","\n","train_split = int(len(X)*0.8)\n","val_split = train_split+int(len(X)*0.1)\n","\n","X_train = X[:train_split]\n","X_test = X[train_split:val_split]\n","# X_val = X[val_split:]\n","Y_train = Y[:train_split]\n","Y_test = Y[train_split:val_split]\n","# X_val = X[val_split:]\n","\n","X_train_norm = X_train/X_train.max()\n","X_test_norm = X_test/X_test.max()\n","X_train_norm = np.expand_dims(X_train_norm,axis=3)\n","X_test_norm = np.expand_dims(X_test_norm,axis=3)\n","\n","\n","batch_size = 32\n","seed = 42\n","\n","def random_180(img):\n","    turns = randint(0,2)\n","    turns  = turns*2\n","    return np.rot90(img,turns)\n","\n","train_datagen = ImageDataGenerator(\n","        rotation_range = 5,\n","        zoom_range=0.3,\n","        horizontal_flip=False,\n","        vertical_flip = False)\n","\n","test_datagen = ImageDataGenerator(\n","        rotation_range = 5,\n","        zoom_range=0.3,\n","        horizontal_flip=False,\n","        vertical_flip = False)\n","\n","\n","\n","train_generator = train_datagen.flow(X_train_norm, y=Y_train, batch_size=batch_size,seed=seed)\n","val_generator = test_datagen.flow(X_test_norm,y=Y_test,batch_size=batch_size,seed=seed)\n","\n","\n","modelE = keras.models.Sequential()\n","modelE.add(Conv2D(64, (3, 3), input_shape=(28, 28,1)))\n","modelE.add(Activation('relu'))\n","modelE.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\n","modelE.add(Conv2D(64, (3, 3)))\n","modelE.add(Activation('relu'))\n","modelE.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","modelE.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n","modelE.add(Dense(64))\n","modelE.add(Activation('relu'))\n","modelE.add(Dropout(0.5))\n","modelE.add(Dense(1))\n","modelE.add(Activation('sigmoid'))\n","\n","modelE.compile(loss='binary_crossentropy',\n","              optimizer='Adadelta',\n","              metrics=['accuracy'])\n","\n","\n","modelCheckpoint = ModelCheckpoint(save_weights,\n","                                  monitor = 'val_loss',\n","                                  save_best_only = True,\n","                                  mode = 'min',\n","                                  verbose = 2,\n","                                  save_weights_only = True)\n","callbacks_list = [modelCheckpoint]\n","history = modelE.fit_generator(\n","        train_generator,\n","        steps_per_epoch=2870,\n","        epochs=100,\n","        validation_data=val_generator,\n","        validation_steps=358,\n","        verbose = 0,\n","        callbacks=callbacks_list)\n","modelE.save_weights(save_weights)\n","h = h5py.File(save_history,'w')\n","h_keys = history.history.keys()\n","for k in h_keys:\n","    h.create_dataset(k,data=history.history[k])\n","h.close()\n","\n","print(modelE.evaluate(X_test_norm,Y_test))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["\n","Epoch 00001: val_loss improved from inf to 0.67617, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00002: val_loss improved from 0.67617 to 0.66164, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00003: val_loss improved from 0.66164 to 0.64878, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00004: val_loss improved from 0.64878 to 0.63792, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00005: val_loss improved from 0.63792 to 0.63205, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00006: val_loss improved from 0.63205 to 0.62957, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00007: val_loss improved from 0.62957 to 0.62757, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00008: val_loss improved from 0.62757 to 0.62373, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00009: val_loss did not improve from 0.62373\n","\n","Epoch 00010: val_loss did not improve from 0.62373\n","\n","Epoch 00011: val_loss did not improve from 0.62373\n","\n","Epoch 00012: val_loss improved from 0.62373 to 0.62315, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00013: val_loss improved from 0.62315 to 0.62182, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00014: val_loss did not improve from 0.62182\n","\n","Epoch 00015: val_loss improved from 0.62182 to 0.62157, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00016: val_loss improved from 0.62157 to 0.62127, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00017: val_loss did not improve from 0.62127\n","\n","Epoch 00018: val_loss improved from 0.62127 to 0.62059, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00019: val_loss did not improve from 0.62059\n","\n","Epoch 00020: val_loss improved from 0.62059 to 0.62055, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00021: val_loss did not improve from 0.62055\n","\n","Epoch 00022: val_loss did not improve from 0.62055\n","\n","Epoch 00023: val_loss improved from 0.62055 to 0.61942, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00024: val_loss did not improve from 0.61942\n","\n","Epoch 00025: val_loss did not improve from 0.61942\n","\n","Epoch 00026: val_loss did not improve from 0.61942\n","\n","Epoch 00027: val_loss did not improve from 0.61942\n","\n","Epoch 00028: val_loss improved from 0.61942 to 0.61854, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00029: val_loss did not improve from 0.61854\n","\n","Epoch 00030: val_loss improved from 0.61854 to 0.61840, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00031: val_loss did not improve from 0.61840\n","\n","Epoch 00032: val_loss did not improve from 0.61840\n","\n","Epoch 00033: val_loss did not improve from 0.61840\n","\n","Epoch 00034: val_loss did not improve from 0.61840\n","\n","Epoch 00035: val_loss improved from 0.61840 to 0.61766, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00036: val_loss did not improve from 0.61766\n","\n","Epoch 00037: val_loss did not improve from 0.61766\n","\n","Epoch 00038: val_loss did not improve from 0.61766\n","\n","Epoch 00039: val_loss did not improve from 0.61766\n","\n","Epoch 00040: val_loss improved from 0.61766 to 0.61683, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00041: val_loss did not improve from 0.61683\n","\n","Epoch 00042: val_loss did not improve from 0.61683\n","\n","Epoch 00043: val_loss did not improve from 0.61683\n","\n","Epoch 00044: val_loss did not improve from 0.61683\n","\n","Epoch 00045: val_loss did not improve from 0.61683\n","\n","Epoch 00046: val_loss did not improve from 0.61683\n","\n","Epoch 00047: val_loss did not improve from 0.61683\n","\n","Epoch 00048: val_loss did not improve from 0.61683\n","\n","Epoch 00049: val_loss did not improve from 0.61683\n","\n","Epoch 00050: val_loss did not improve from 0.61683\n","\n","Epoch 00051: val_loss did not improve from 0.61683\n","\n","Epoch 00052: val_loss did not improve from 0.61683\n","\n","Epoch 00053: val_loss did not improve from 0.61683\n","\n","Epoch 00054: val_loss did not improve from 0.61683\n","\n","Epoch 00055: val_loss did not improve from 0.61683\n","\n","Epoch 00056: val_loss did not improve from 0.61683\n","\n","Epoch 00057: val_loss did not improve from 0.61683\n","\n","Epoch 00058: val_loss did not improve from 0.61683\n","\n","Epoch 00059: val_loss did not improve from 0.61683\n","\n","Epoch 00060: val_loss did not improve from 0.61683\n","\n","Epoch 00061: val_loss did not improve from 0.61683\n","\n","Epoch 00062: val_loss did not improve from 0.61683\n","\n","Epoch 00063: val_loss improved from 0.61683 to 0.61671, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00064: val_loss did not improve from 0.61671\n","\n","Epoch 00065: val_loss did not improve from 0.61671\n","\n","Epoch 00066: val_loss did not improve from 0.61671\n","\n","Epoch 00067: val_loss did not improve from 0.61671\n","\n","Epoch 00068: val_loss improved from 0.61671 to 0.61630, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00069: val_loss did not improve from 0.61630\n","\n","Epoch 00070: val_loss improved from 0.61630 to 0.61600, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00071: val_loss did not improve from 0.61600\n","\n","Epoch 00072: val_loss did not improve from 0.61600\n","\n","Epoch 00073: val_loss did not improve from 0.61600\n","\n","Epoch 00074: val_loss did not improve from 0.61600\n","\n","Epoch 00075: val_loss improved from 0.61600 to 0.61545, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00076: val_loss did not improve from 0.61545\n","\n","Epoch 00077: val_loss did not improve from 0.61545\n","\n","Epoch 00078: val_loss did not improve from 0.61545\n","\n","Epoch 00079: val_loss did not improve from 0.61545\n","\n","Epoch 00080: val_loss did not improve from 0.61545\n","\n","Epoch 00081: val_loss did not improve from 0.61545\n","\n","Epoch 00082: val_loss did not improve from 0.61545\n","\n","Epoch 00083: val_loss did not improve from 0.61545\n","\n","Epoch 00084: val_loss did not improve from 0.61545\n","\n","Epoch 00085: val_loss did not improve from 0.61545\n","\n","Epoch 00086: val_loss did not improve from 0.61545\n","\n","Epoch 00087: val_loss did not improve from 0.61545\n","\n","Epoch 00088: val_loss did not improve from 0.61545\n","\n","Epoch 00089: val_loss did not improve from 0.61545\n","\n","Epoch 00090: val_loss did not improve from 0.61545\n","\n","Epoch 00091: val_loss did not improve from 0.61545\n","\n","Epoch 00092: val_loss did not improve from 0.61545\n","\n","Epoch 00093: val_loss improved from 0.61545 to 0.61490, saving model to /content/drive/My Drive/colab/30perror_weights_v9.h5\n","\n","Epoch 00094: val_loss did not improve from 0.61490\n","\n","Epoch 00095: val_loss did not improve from 0.61490\n","\n","Epoch 00096: val_loss did not improve from 0.61490\n","\n","Epoch 00097: val_loss did not improve from 0.61490\n","\n","Epoch 00098: val_loss did not improve from 0.61490\n","\n","Epoch 00099: val_loss did not improve from 0.61490\n","\n","Epoch 00100: val_loss did not improve from 0.61490\n","1253/1253 [==============================] - 0s 58us/sample - loss: 0.6169 - acc: 0.6935\n","[0.6168690230117639, 0.6935355]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ey2zhw9ItsLc","executionInfo":{"status":"ok","timestamp":1618974152185,"user_tz":420,"elapsed":10301437,"user":{"displayName":"Kate Groschner","photoUrl":"","userId":"03462860494048042586"}},"outputId":"5c942962-149e-4d3b-c4df-cd7782cd80c6"},"source":["wrong_frac = 0.4\n","version = 9\n","name_frac = str(wrong_frac).split('.')[-1]\n","if len(name_frac) == 1:\n","    name_frac = name_frac + '0'\n","if len(name_frac) == 1:\n","    name_frac = name_frac + '0'\n","save_weights = '/content/drive/My Drive/colab/'+ name_frac +'perror_weights_v'+ str(version) + '.h5'\n","save_history = '/content/drive/My Drive/colab/'+ name_frac +'perror_history_v'+ str(version) + '.h5'\n","\n","\n","seven_imgs_train = []\n","seven_labels_train = []\n","for idx,label in enumerate(data[0][1]):\n","    if label == 7:\n","        seven_imgs_train.append(data[0][0][idx])\n","        seven_labels_train.append(label)\n","seven_imgs_train = np.array(seven_imgs_train)\n","seven_labels_train = np.array(seven_labels_train)\n","\n","\n","new_left_images = []\n","new_left_labels = []\n","new_right_images = []\n","new_right_labels = []\n","\n","for img in seven_imgs_train:\n","    new_left_images.append(np.fliplr(img))\n","    new_left_labels.append(0)\n","    new_right_images.append(img)\n","    new_right_labels.append(1)\n","new_left_images = np.array(new_left_images)\n","new_right_images = np.array(new_right_images)\n","\n","split = int(seven_imgs_train.shape[0]*wrong_frac)\n","\n","for idx in np.arange(0,split):\n","    new_right_images[idx] = np.fliplr(new_right_images[idx])\n","\n","for idx in np.arange(0,split):\n","    new_left_images[idx] = np.fliplr(new_left_images[idx])\n","\n","\n","X = utils.shuffle(np.concatenate((new_right_images,new_left_images),axis =0),random_state=0)\n","Y = utils.shuffle(np.concatenate((new_right_labels,new_left_labels),axis = 0),random_state=0)\n","\n","train_split = int(len(X)*0.8)\n","val_split = train_split+int(len(X)*0.1)\n","\n","X_train = X[:train_split]\n","X_test = X[train_split:val_split]\n","# X_val = X[val_split:]\n","Y_train = Y[:train_split]\n","Y_test = Y[train_split:val_split]\n","# X_val = X[val_split:]\n","\n","X_train_norm = X_train/X_train.max()\n","X_test_norm = X_test/X_test.max()\n","X_train_norm = np.expand_dims(X_train_norm,axis=3)\n","X_test_norm = np.expand_dims(X_test_norm,axis=3)\n","\n","\n","batch_size = 32\n","seed = 42\n","\n","def random_180(img):\n","    turns = randint(0,2)\n","    turns  = turns*2\n","    return np.rot90(img,turns)\n","\n","train_datagen = ImageDataGenerator(\n","        rotation_range = 5,\n","        zoom_range=0.3,\n","        horizontal_flip=False,\n","        vertical_flip = False)\n","\n","test_datagen = ImageDataGenerator(\n","        rotation_range = 5,\n","        zoom_range=0.3,\n","        horizontal_flip=False,\n","        vertical_flip = False)\n","\n","\n","\n","train_generator = train_datagen.flow(X_train_norm, y=Y_train, batch_size=batch_size,seed=seed)\n","val_generator = test_datagen.flow(X_test_norm,y=Y_test,batch_size=batch_size,seed=seed)\n","\n","\n","modelE = keras.models.Sequential()\n","modelE.add(Conv2D(64, (3, 3), input_shape=(28, 28,1)))\n","modelE.add(Activation('relu'))\n","modelE.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\n","modelE.add(Conv2D(64, (3, 3)))\n","modelE.add(Activation('relu'))\n","modelE.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","modelE.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n","modelE.add(Dense(64))\n","modelE.add(Activation('relu'))\n","modelE.add(Dropout(0.5))\n","modelE.add(Dense(1))\n","modelE.add(Activation('sigmoid'))\n","\n","modelE.compile(loss='binary_crossentropy',\n","              optimizer='Adadelta',\n","              metrics=['accuracy'])\n","\n","\n","modelCheckpoint = ModelCheckpoint(save_weights,\n","                                  monitor = 'val_loss',\n","                                  save_best_only = True,\n","                                  mode = 'min',\n","                                  verbose = 2,\n","                                  save_weights_only = True)\n","callbacks_list = [modelCheckpoint]\n","history = modelE.fit_generator(\n","        train_generator,\n","        steps_per_epoch=2870,\n","        epochs=100,\n","        validation_data=val_generator,\n","        validation_steps=358,\n","        verbose = 0,\n","        callbacks=callbacks_list)\n","modelE.save_weights(save_weights)\n","h = h5py.File(save_history,'w')\n","h_keys = history.history.keys()\n","for k in h_keys:\n","    h.create_dataset(k,data=history.history[k])\n","h.close()\n","\n","print(modelE.evaluate(X_test_norm,Y_test))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["\n","Epoch 00001: val_loss improved from inf to 0.68726, saving model to /content/drive/My Drive/colab/40perror_weights_v9.h5\n","\n","Epoch 00002: val_loss improved from 0.68726 to 0.68395, saving model to /content/drive/My Drive/colab/40perror_weights_v9.h5\n","\n","Epoch 00003: val_loss improved from 0.68395 to 0.68151, saving model to /content/drive/My Drive/colab/40perror_weights_v9.h5\n","\n","Epoch 00004: val_loss improved from 0.68151 to 0.67941, saving model to /content/drive/My Drive/colab/40perror_weights_v9.h5\n","\n","Epoch 00005: val_loss improved from 0.67941 to 0.67888, saving model to /content/drive/My Drive/colab/40perror_weights_v9.h5\n","\n","Epoch 00006: val_loss improved from 0.67888 to 0.67806, saving model to /content/drive/My Drive/colab/40perror_weights_v9.h5\n","\n","Epoch 00007: val_loss improved from 0.67806 to 0.67724, saving model to /content/drive/My Drive/colab/40perror_weights_v9.h5\n","\n","Epoch 00008: val_loss improved from 0.67724 to 0.67552, saving model to /content/drive/My Drive/colab/40perror_weights_v9.h5\n","\n","Epoch 00009: val_loss did not improve from 0.67552\n","\n","Epoch 00010: val_loss improved from 0.67552 to 0.67546, saving model to /content/drive/My Drive/colab/40perror_weights_v9.h5\n","\n","Epoch 00011: val_loss did not improve from 0.67546\n","\n","Epoch 00012: val_loss improved from 0.67546 to 0.67445, saving model to /content/drive/My Drive/colab/40perror_weights_v9.h5\n","\n","Epoch 00013: val_loss improved from 0.67445 to 0.67391, saving model to /content/drive/My Drive/colab/40perror_weights_v9.h5\n","\n","Epoch 00014: val_loss did not improve from 0.67391\n","\n","Epoch 00015: val_loss improved from 0.67391 to 0.67309, saving model to /content/drive/My Drive/colab/40perror_weights_v9.h5\n","\n","Epoch 00016: val_loss did not improve from 0.67309\n","\n","Epoch 00017: val_loss did not improve from 0.67309\n","\n","Epoch 00018: val_loss improved from 0.67309 to 0.67253, saving model to /content/drive/My Drive/colab/40perror_weights_v9.h5\n","\n","Epoch 00019: val_loss did not improve from 0.67253\n","\n","Epoch 00020: val_loss did not improve from 0.67253\n","\n","Epoch 00021: val_loss did not improve from 0.67253\n","\n","Epoch 00022: val_loss did not improve from 0.67253\n","\n","Epoch 00023: val_loss improved from 0.67253 to 0.67208, saving model to /content/drive/My Drive/colab/40perror_weights_v9.h5\n","\n","Epoch 00024: val_loss did not improve from 0.67208\n","\n","Epoch 00025: val_loss did not improve from 0.67208\n","\n","Epoch 00026: val_loss improved from 0.67208 to 0.67171, saving model to /content/drive/My Drive/colab/40perror_weights_v9.h5\n","\n","Epoch 00027: val_loss did not improve from 0.67171\n","\n","Epoch 00028: val_loss improved from 0.67171 to 0.67109, saving model to /content/drive/My Drive/colab/40perror_weights_v9.h5\n","\n","Epoch 00029: val_loss did not improve from 0.67109\n","\n","Epoch 00030: val_loss did not improve from 0.67109\n","\n","Epoch 00031: val_loss did not improve from 0.67109\n","\n","Epoch 00032: val_loss did not improve from 0.67109\n","\n","Epoch 00033: val_loss did not improve from 0.67109\n","\n","Epoch 00034: val_loss did not improve from 0.67109\n","\n","Epoch 00035: val_loss did not improve from 0.67109\n","\n","Epoch 00036: val_loss did not improve from 0.67109\n","\n","Epoch 00037: val_loss did not improve from 0.67109\n","\n","Epoch 00038: val_loss did not improve from 0.67109\n","\n","Epoch 00039: val_loss did not improve from 0.67109\n","\n","Epoch 00040: val_loss improved from 0.67109 to 0.67050, saving model to /content/drive/My Drive/colab/40perror_weights_v9.h5\n","\n","Epoch 00041: val_loss did not improve from 0.67050\n","\n","Epoch 00042: val_loss did not improve from 0.67050\n","\n","Epoch 00043: val_loss did not improve from 0.67050\n","\n","Epoch 00044: val_loss did not improve from 0.67050\n","\n","Epoch 00045: val_loss did not improve from 0.67050\n","\n","Epoch 00046: val_loss did not improve from 0.67050\n","\n","Epoch 00047: val_loss did not improve from 0.67050\n","\n","Epoch 00048: val_loss did not improve from 0.67050\n","\n","Epoch 00049: val_loss did not improve from 0.67050\n","\n","Epoch 00050: val_loss did not improve from 0.67050\n","\n","Epoch 00051: val_loss did not improve from 0.67050\n","\n","Epoch 00052: val_loss did not improve from 0.67050\n","\n","Epoch 00053: val_loss did not improve from 0.67050\n","\n","Epoch 00054: val_loss did not improve from 0.67050\n","\n","Epoch 00055: val_loss did not improve from 0.67050\n","\n","Epoch 00056: val_loss did not improve from 0.67050\n","\n","Epoch 00057: val_loss did not improve from 0.67050\n","\n","Epoch 00058: val_loss did not improve from 0.67050\n","\n","Epoch 00059: val_loss did not improve from 0.67050\n","\n","Epoch 00060: val_loss did not improve from 0.67050\n","\n","Epoch 00061: val_loss did not improve from 0.67050\n","\n","Epoch 00062: val_loss did not improve from 0.67050\n","\n","Epoch 00063: val_loss did not improve from 0.67050\n","\n","Epoch 00064: val_loss did not improve from 0.67050\n","\n","Epoch 00065: val_loss did not improve from 0.67050\n","\n","Epoch 00066: val_loss did not improve from 0.67050\n","\n","Epoch 00067: val_loss did not improve from 0.67050\n","\n","Epoch 00068: val_loss did not improve from 0.67050\n","\n","Epoch 00069: val_loss did not improve from 0.67050\n","\n","Epoch 00070: val_loss did not improve from 0.67050\n","\n","Epoch 00071: val_loss did not improve from 0.67050\n","\n","Epoch 00072: val_loss did not improve from 0.67050\n","\n","Epoch 00073: val_loss did not improve from 0.67050\n","\n","Epoch 00074: val_loss did not improve from 0.67050\n","\n","Epoch 00075: val_loss improved from 0.67050 to 0.67033, saving model to /content/drive/My Drive/colab/40perror_weights_v9.h5\n","\n","Epoch 00076: val_loss did not improve from 0.67033\n","\n","Epoch 00077: val_loss did not improve from 0.67033\n","\n","Epoch 00078: val_loss did not improve from 0.67033\n","\n","Epoch 00079: val_loss improved from 0.67033 to 0.67028, saving model to /content/drive/My Drive/colab/40perror_weights_v9.h5\n","\n","Epoch 00080: val_loss did not improve from 0.67028\n","\n","Epoch 00081: val_loss did not improve from 0.67028\n","\n","Epoch 00082: val_loss did not improve from 0.67028\n","\n","Epoch 00083: val_loss did not improve from 0.67028\n","\n","Epoch 00084: val_loss did not improve from 0.67028\n","\n","Epoch 00085: val_loss did not improve from 0.67028\n","\n","Epoch 00086: val_loss did not improve from 0.67028\n","\n","Epoch 00087: val_loss did not improve from 0.67028\n","\n","Epoch 00088: val_loss did not improve from 0.67028\n","\n","Epoch 00089: val_loss did not improve from 0.67028\n","\n","Epoch 00090: val_loss did not improve from 0.67028\n","\n","Epoch 00091: val_loss did not improve from 0.67028\n","\n","Epoch 00092: val_loss did not improve from 0.67028\n","\n","Epoch 00093: val_loss did not improve from 0.67028\n","\n","Epoch 00094: val_loss did not improve from 0.67028\n","\n","Epoch 00095: val_loss did not improve from 0.67028\n","\n","Epoch 00096: val_loss did not improve from 0.67028\n","\n","Epoch 00097: val_loss did not improve from 0.67028\n","\n","Epoch 00098: val_loss did not improve from 0.67028\n","\n","Epoch 00099: val_loss improved from 0.67028 to 0.67010, saving model to /content/drive/My Drive/colab/40perror_weights_v9.h5\n","\n","Epoch 00100: val_loss did not improve from 0.67010\n","1253/1253 [==============================] - 0s 64us/sample - loss: 0.6706 - acc: 0.6057\n","[0.670649423041728, 0.6057462]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qL-G2ahbUdtj","executionInfo":{"status":"ok","timestamp":1618976743023,"user_tz":420,"elapsed":12892272,"user":{"displayName":"Kate Groschner","photoUrl":"","userId":"03462860494048042586"}},"outputId":"beff4fca-bd50-4654-ef0b-4748242db1cf"},"source":["wrong_frac = 0.42\n","version = 9\n","name_frac = str(wrong_frac).split('.')[-1]\n","if len(name_frac) == 1:\n","    name_frac = name_frac + '0'\n","if len(name_frac) == 1:\n","    name_frac = name_frac + '0'\n","save_weights = '/content/drive/My Drive/colab/'+ name_frac +'perror_weights_v'+ str(version) + '.h5'\n","save_history = '/content/drive/My Drive/colab/'+ name_frac +'perror_history_v'+ str(version) + '.h5'\n","\n","\n","seven_imgs_train = []\n","seven_labels_train = []\n","for idx,label in enumerate(data[0][1]):\n","    if label == 7:\n","        seven_imgs_train.append(data[0][0][idx])\n","        seven_labels_train.append(label)\n","seven_imgs_train = np.array(seven_imgs_train)\n","seven_labels_train = np.array(seven_labels_train)\n","\n","\n","new_left_images = []\n","new_left_labels = []\n","new_right_images = []\n","new_right_labels = []\n","\n","for img in seven_imgs_train:\n","    new_left_images.append(np.fliplr(img))\n","    new_left_labels.append(0)\n","    new_right_images.append(img)\n","    new_right_labels.append(1)\n","new_left_images = np.array(new_left_images)\n","new_right_images = np.array(new_right_images)\n","\n","split = int(seven_imgs_train.shape[0]*wrong_frac)\n","\n","for idx in np.arange(0,split):\n","    new_right_images[idx] = np.fliplr(new_right_images[idx])\n","\n","for idx in np.arange(0,split):\n","    new_left_images[idx] = np.fliplr(new_left_images[idx])\n","\n","\n","X = utils.shuffle(np.concatenate((new_right_images,new_left_images),axis =0),random_state=0)\n","Y = utils.shuffle(np.concatenate((new_right_labels,new_left_labels),axis = 0),random_state=0)\n","\n","train_split = int(len(X)*0.8)\n","val_split = train_split+int(len(X)*0.1)\n","\n","X_train = X[:train_split]\n","X_test = X[train_split:val_split]\n","# X_val = X[val_split:]\n","Y_train = Y[:train_split]\n","Y_test = Y[train_split:val_split]\n","# X_val = X[val_split:]\n","\n","X_train_norm = X_train/X_train.max()\n","X_test_norm = X_test/X_test.max()\n","X_train_norm = np.expand_dims(X_train_norm,axis=3)\n","X_test_norm = np.expand_dims(X_test_norm,axis=3)\n","\n","\n","batch_size = 32\n","seed = 42\n","\n","def random_180(img):\n","    turns = randint(0,2)\n","    turns  = turns*2\n","    return np.rot90(img,turns)\n","\n","train_datagen = ImageDataGenerator(\n","        rotation_range = 5,\n","        zoom_range=0.3,\n","        horizontal_flip=False,\n","        vertical_flip = False)\n","\n","test_datagen = ImageDataGenerator(\n","        rotation_range = 5,\n","        zoom_range=0.3,\n","        horizontal_flip=False,\n","        vertical_flip = False)\n","\n","\n","\n","train_generator = train_datagen.flow(X_train_norm, y=Y_train, batch_size=batch_size,seed=seed)\n","val_generator = test_datagen.flow(X_test_norm,y=Y_test,batch_size=batch_size,seed=seed)\n","\n","\n","modelE = keras.models.Sequential()\n","modelE.add(Conv2D(64, (3, 3), input_shape=(28, 28,1)))\n","modelE.add(Activation('relu'))\n","modelE.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\n","modelE.add(Conv2D(64, (3, 3)))\n","modelE.add(Activation('relu'))\n","modelE.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","modelE.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n","modelE.add(Dense(64))\n","modelE.add(Activation('relu'))\n","modelE.add(Dropout(0.5))\n","modelE.add(Dense(1))\n","modelE.add(Activation('sigmoid'))\n","\n","modelE.compile(loss='binary_crossentropy',\n","              optimizer='Adadelta',\n","              metrics=['accuracy'])\n","\n","\n","modelCheckpoint = ModelCheckpoint(save_weights,\n","                                  monitor = 'val_loss',\n","                                  save_best_only = True,\n","                                  mode = 'min',\n","                                  verbose = 2,\n","                                  save_weights_only = True)\n","callbacks_list = [modelCheckpoint]\n","history = modelE.fit_generator(\n","        train_generator,\n","        steps_per_epoch=2870,\n","        epochs=100,\n","        validation_data=val_generator,\n","        validation_steps=358,\n","        verbose = 0,\n","        callbacks=callbacks_list)\n","modelE.save_weights(save_weights)\n","h = h5py.File(save_history,'w')\n","h_keys = history.history.keys()\n","for k in h_keys:\n","    h.create_dataset(k,data=history.history[k])\n","h.close()\n","\n","print(modelE.evaluate(X_test_norm,Y_test))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["\n","Epoch 00001: val_loss improved from inf to 0.69101, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00002: val_loss improved from 0.69101 to 0.68951, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00003: val_loss improved from 0.68951 to 0.68802, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00004: val_loss improved from 0.68802 to 0.68654, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00005: val_loss improved from 0.68654 to 0.68541, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00006: val_loss improved from 0.68541 to 0.68467, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00007: val_loss improved from 0.68467 to 0.68373, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00008: val_loss improved from 0.68373 to 0.68229, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00009: val_loss improved from 0.68229 to 0.68221, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00010: val_loss improved from 0.68221 to 0.68173, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00011: val_loss improved from 0.68173 to 0.68136, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00012: val_loss improved from 0.68136 to 0.68064, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00013: val_loss improved from 0.68064 to 0.67981, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00014: val_loss did not improve from 0.67981\n","\n","Epoch 00015: val_loss improved from 0.67981 to 0.67922, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00016: val_loss did not improve from 0.67922\n","\n","Epoch 00017: val_loss improved from 0.67922 to 0.67920, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00018: val_loss improved from 0.67920 to 0.67822, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00019: val_loss did not improve from 0.67822\n","\n","Epoch 00020: val_loss did not improve from 0.67822\n","\n","Epoch 00021: val_loss did not improve from 0.67822\n","\n","Epoch 00022: val_loss did not improve from 0.67822\n","\n","Epoch 00023: val_loss improved from 0.67822 to 0.67802, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00024: val_loss did not improve from 0.67802\n","\n","Epoch 00025: val_loss did not improve from 0.67802\n","\n","Epoch 00026: val_loss improved from 0.67802 to 0.67744, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00027: val_loss did not improve from 0.67744\n","\n","Epoch 00028: val_loss improved from 0.67744 to 0.67712, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00029: val_loss did not improve from 0.67712\n","\n","Epoch 00030: val_loss did not improve from 0.67712\n","\n","Epoch 00031: val_loss did not improve from 0.67712\n","\n","Epoch 00032: val_loss improved from 0.67712 to 0.67710, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00033: val_loss did not improve from 0.67710\n","\n","Epoch 00034: val_loss improved from 0.67710 to 0.67705, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00035: val_loss improved from 0.67705 to 0.67695, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00036: val_loss did not improve from 0.67695\n","\n","Epoch 00037: val_loss did not improve from 0.67695\n","\n","Epoch 00038: val_loss did not improve from 0.67695\n","\n","Epoch 00039: val_loss did not improve from 0.67695\n","\n","Epoch 00040: val_loss improved from 0.67695 to 0.67619, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00041: val_loss did not improve from 0.67619\n","\n","Epoch 00042: val_loss did not improve from 0.67619\n","\n","Epoch 00043: val_loss did not improve from 0.67619\n","\n","Epoch 00044: val_loss did not improve from 0.67619\n","\n","Epoch 00045: val_loss did not improve from 0.67619\n","\n","Epoch 00046: val_loss did not improve from 0.67619\n","\n","Epoch 00047: val_loss did not improve from 0.67619\n","\n","Epoch 00048: val_loss did not improve from 0.67619\n","\n","Epoch 00049: val_loss improved from 0.67619 to 0.67614, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00050: val_loss did not improve from 0.67614\n","\n","Epoch 00051: val_loss did not improve from 0.67614\n","\n","Epoch 00052: val_loss did not improve from 0.67614\n","\n","Epoch 00053: val_loss did not improve from 0.67614\n","\n","Epoch 00054: val_loss did not improve from 0.67614\n","\n","Epoch 00055: val_loss did not improve from 0.67614\n","\n","Epoch 00056: val_loss did not improve from 0.67614\n","\n","Epoch 00057: val_loss did not improve from 0.67614\n","\n","Epoch 00058: val_loss did not improve from 0.67614\n","\n","Epoch 00059: val_loss did not improve from 0.67614\n","\n","Epoch 00060: val_loss did not improve from 0.67614\n","\n","Epoch 00061: val_loss did not improve from 0.67614\n","\n","Epoch 00062: val_loss did not improve from 0.67614\n","\n","Epoch 00063: val_loss did not improve from 0.67614\n","\n","Epoch 00064: val_loss did not improve from 0.67614\n","\n","Epoch 00065: val_loss did not improve from 0.67614\n","\n","Epoch 00066: val_loss did not improve from 0.67614\n","\n","Epoch 00067: val_loss did not improve from 0.67614\n","\n","Epoch 00068: val_loss did not improve from 0.67614\n","\n","Epoch 00069: val_loss did not improve from 0.67614\n","\n","Epoch 00070: val_loss improved from 0.67614 to 0.67611, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00071: val_loss did not improve from 0.67611\n","\n","Epoch 00072: val_loss improved from 0.67611 to 0.67558, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00073: val_loss did not improve from 0.67558\n","\n","Epoch 00074: val_loss did not improve from 0.67558\n","\n","Epoch 00075: val_loss did not improve from 0.67558\n","\n","Epoch 00076: val_loss did not improve from 0.67558\n","\n","Epoch 00077: val_loss did not improve from 0.67558\n","\n","Epoch 00078: val_loss did not improve from 0.67558\n","\n","Epoch 00079: val_loss improved from 0.67558 to 0.67546, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00080: val_loss did not improve from 0.67546\n","\n","Epoch 00081: val_loss did not improve from 0.67546\n","\n","Epoch 00082: val_loss improved from 0.67546 to 0.67540, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00083: val_loss did not improve from 0.67540\n","\n","Epoch 00084: val_loss did not improve from 0.67540\n","\n","Epoch 00085: val_loss did not improve from 0.67540\n","\n","Epoch 00086: val_loss did not improve from 0.67540\n","\n","Epoch 00087: val_loss did not improve from 0.67540\n","\n","Epoch 00088: val_loss did not improve from 0.67540\n","\n","Epoch 00089: val_loss did not improve from 0.67540\n","\n","Epoch 00090: val_loss did not improve from 0.67540\n","\n","Epoch 00091: val_loss did not improve from 0.67540\n","\n","Epoch 00092: val_loss did not improve from 0.67540\n","\n","Epoch 00093: val_loss did not improve from 0.67540\n","\n","Epoch 00094: val_loss did not improve from 0.67540\n","\n","Epoch 00095: val_loss did not improve from 0.67540\n","\n","Epoch 00096: val_loss did not improve from 0.67540\n","\n","Epoch 00097: val_loss improved from 0.67540 to 0.67537, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00098: val_loss did not improve from 0.67537\n","\n","Epoch 00099: val_loss improved from 0.67537 to 0.67511, saving model to /content/drive/My Drive/colab/42perror_weights_v9.h5\n","\n","Epoch 00100: val_loss did not improve from 0.67511\n","1253/1253 [==============================] - 0s 61us/sample - loss: 0.6742 - acc: 0.5938\n","[0.6741678181021858, 0.5937749]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jcFxLU5NZ5V6","executionInfo":{"status":"ok","timestamp":1618979338920,"user_tz":420,"elapsed":15488166,"user":{"displayName":"Kate Groschner","photoUrl":"","userId":"03462860494048042586"}},"outputId":"effe96f2-8f7b-4779-d3ca-f32a5ebf2b43"},"source":["wrong_frac = 0.46\n","version = 9\n","name_frac = str(wrong_frac).split('.')[-1]\n","if len(name_frac) == 1:\n","    name_frac = name_frac + '0'\n","if len(name_frac) == 1:\n","    name_frac = name_frac + '0'\n","save_weights = '/content/drive/My Drive/colab/'+ name_frac +'perror_weights_v'+ str(version) + '.h5'\n","save_history = '/content/drive/My Drive/colab/'+ name_frac +'perror_history_v'+ str(version) + '.h5'\n","\n","\n","seven_imgs_train = []\n","seven_labels_train = []\n","for idx,label in enumerate(data[0][1]):\n","    if label == 7:\n","        seven_imgs_train.append(data[0][0][idx])\n","        seven_labels_train.append(label)\n","seven_imgs_train = np.array(seven_imgs_train)\n","seven_labels_train = np.array(seven_labels_train)\n","\n","\n","new_left_images = []\n","new_left_labels = []\n","new_right_images = []\n","new_right_labels = []\n","\n","for img in seven_imgs_train:\n","    new_left_images.append(np.fliplr(img))\n","    new_left_labels.append(0)\n","    new_right_images.append(img)\n","    new_right_labels.append(1)\n","new_left_images = np.array(new_left_images)\n","new_right_images = np.array(new_right_images)\n","\n","split = int(seven_imgs_train.shape[0]*wrong_frac)\n","\n","for idx in np.arange(0,split):\n","    new_right_images[idx] = np.fliplr(new_right_images[idx])\n","\n","for idx in np.arange(0,split):\n","    new_left_images[idx] = np.fliplr(new_left_images[idx])\n","\n","\n","X = utils.shuffle(np.concatenate((new_right_images,new_left_images),axis =0),random_state=0)\n","Y = utils.shuffle(np.concatenate((new_right_labels,new_left_labels),axis = 0),random_state=0)\n","\n","train_split = int(len(X)*0.8)\n","val_split = train_split+int(len(X)*0.1)\n","\n","X_train = X[:train_split]\n","X_test = X[train_split:val_split]\n","# X_val = X[val_split:]\n","Y_train = Y[:train_split]\n","Y_test = Y[train_split:val_split]\n","# X_val = X[val_split:]\n","\n","X_train_norm = X_train/X_train.max()\n","X_test_norm = X_test/X_test.max()\n","X_train_norm = np.expand_dims(X_train_norm,axis=3)\n","X_test_norm = np.expand_dims(X_test_norm,axis=3)\n","\n","\n","batch_size = 32\n","seed = 42\n","\n","def random_180(img):\n","    turns = randint(0,2)\n","    turns  = turns*2\n","    return np.rot90(img,turns)\n","\n","train_datagen = ImageDataGenerator(\n","        rotation_range = 5,\n","        zoom_range=0.3,\n","        horizontal_flip=False,\n","        vertical_flip = False)\n","\n","test_datagen = ImageDataGenerator(\n","        rotation_range = 5,\n","        zoom_range=0.3,\n","        horizontal_flip=False,\n","        vertical_flip = False)\n","\n","\n","\n","train_generator = train_datagen.flow(X_train_norm, y=Y_train, batch_size=batch_size,seed=seed)\n","val_generator = test_datagen.flow(X_test_norm,y=Y_test,batch_size=batch_size,seed=seed)\n","\n","\n","modelE = keras.models.Sequential()\n","modelE.add(Conv2D(64, (3, 3), input_shape=(28, 28,1)))\n","modelE.add(Activation('relu'))\n","modelE.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\n","modelE.add(Conv2D(64, (3, 3)))\n","modelE.add(Activation('relu'))\n","modelE.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","modelE.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n","modelE.add(Dense(64))\n","modelE.add(Activation('relu'))\n","modelE.add(Dropout(0.5))\n","modelE.add(Dense(1))\n","modelE.add(Activation('sigmoid'))\n","\n","modelE.compile(loss='binary_crossentropy',\n","              optimizer='Adadelta',\n","              metrics=['accuracy'])\n","\n","\n","modelCheckpoint = ModelCheckpoint(save_weights,\n","                                  monitor = 'val_loss',\n","                                  save_best_only = True,\n","                                  mode = 'min',\n","                                  verbose = 2,\n","                                  save_weights_only = True)\n","callbacks_list = [modelCheckpoint]\n","history = modelE.fit_generator(\n","        train_generator,\n","        steps_per_epoch=2870,\n","        epochs=100,\n","        validation_data=val_generator,\n","        validation_steps=358,\n","        verbose = 0,\n","        callbacks=callbacks_list)\n","modelE.save_weights(save_weights)\n","h = h5py.File(save_history,'w')\n","h_keys = history.history.keys()\n","for k in h_keys:\n","    h.create_dataset(k,data=history.history[k])\n","h.close()\n","\n","print(modelE.evaluate(X_test_norm,Y_test))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["\n","Epoch 00001: val_loss improved from inf to 0.69375, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00002: val_loss improved from 0.69375 to 0.69243, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00003: val_loss improved from 0.69243 to 0.69212, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00004: val_loss improved from 0.69212 to 0.69169, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00005: val_loss improved from 0.69169 to 0.69116, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00006: val_loss improved from 0.69116 to 0.69108, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00007: val_loss improved from 0.69108 to 0.69065, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00008: val_loss improved from 0.69065 to 0.69038, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00009: val_loss improved from 0.69038 to 0.69033, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00010: val_loss did not improve from 0.69033\n","\n","Epoch 00011: val_loss improved from 0.69033 to 0.69030, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00012: val_loss improved from 0.69030 to 0.68958, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00013: val_loss improved from 0.68958 to 0.68952, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00014: val_loss did not improve from 0.68952\n","\n","Epoch 00015: val_loss improved from 0.68952 to 0.68932, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00016: val_loss improved from 0.68932 to 0.68912, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00017: val_loss did not improve from 0.68912\n","\n","Epoch 00018: val_loss improved from 0.68912 to 0.68877, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00019: val_loss did not improve from 0.68877\n","\n","Epoch 00020: val_loss did not improve from 0.68877\n","\n","Epoch 00021: val_loss did not improve from 0.68877\n","\n","Epoch 00022: val_loss did not improve from 0.68877\n","\n","Epoch 00023: val_loss improved from 0.68877 to 0.68858, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00024: val_loss did not improve from 0.68858\n","\n","Epoch 00025: val_loss did not improve from 0.68858\n","\n","Epoch 00026: val_loss improved from 0.68858 to 0.68802, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00027: val_loss did not improve from 0.68802\n","\n","Epoch 00028: val_loss did not improve from 0.68802\n","\n","Epoch 00029: val_loss did not improve from 0.68802\n","\n","Epoch 00030: val_loss improved from 0.68802 to 0.68793, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00031: val_loss did not improve from 0.68793\n","\n","Epoch 00032: val_loss did not improve from 0.68793\n","\n","Epoch 00033: val_loss did not improve from 0.68793\n","\n","Epoch 00034: val_loss did not improve from 0.68793\n","\n","Epoch 00035: val_loss did not improve from 0.68793\n","\n","Epoch 00036: val_loss did not improve from 0.68793\n","\n","Epoch 00037: val_loss did not improve from 0.68793\n","\n","Epoch 00038: val_loss improved from 0.68793 to 0.68791, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00039: val_loss did not improve from 0.68791\n","\n","Epoch 00040: val_loss improved from 0.68791 to 0.68757, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00041: val_loss did not improve from 0.68757\n","\n","Epoch 00042: val_loss did not improve from 0.68757\n","\n","Epoch 00043: val_loss did not improve from 0.68757\n","\n","Epoch 00044: val_loss did not improve from 0.68757\n","\n","Epoch 00045: val_loss did not improve from 0.68757\n","\n","Epoch 00046: val_loss did not improve from 0.68757\n","\n","Epoch 00047: val_loss did not improve from 0.68757\n","\n","Epoch 00048: val_loss did not improve from 0.68757\n","\n","Epoch 00049: val_loss improved from 0.68757 to 0.68734, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00050: val_loss did not improve from 0.68734\n","\n","Epoch 00051: val_loss did not improve from 0.68734\n","\n","Epoch 00052: val_loss did not improve from 0.68734\n","\n","Epoch 00053: val_loss did not improve from 0.68734\n","\n","Epoch 00054: val_loss did not improve from 0.68734\n","\n","Epoch 00055: val_loss did not improve from 0.68734\n","\n","Epoch 00056: val_loss did not improve from 0.68734\n","\n","Epoch 00057: val_loss did not improve from 0.68734\n","\n","Epoch 00058: val_loss did not improve from 0.68734\n","\n","Epoch 00059: val_loss improved from 0.68734 to 0.68723, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00060: val_loss did not improve from 0.68723\n","\n","Epoch 00061: val_loss did not improve from 0.68723\n","\n","Epoch 00062: val_loss did not improve from 0.68723\n","\n","Epoch 00063: val_loss did not improve from 0.68723\n","\n","Epoch 00064: val_loss did not improve from 0.68723\n","\n","Epoch 00065: val_loss did not improve from 0.68723\n","\n","Epoch 00066: val_loss did not improve from 0.68723\n","\n","Epoch 00067: val_loss did not improve from 0.68723\n","\n","Epoch 00068: val_loss did not improve from 0.68723\n","\n","Epoch 00069: val_loss improved from 0.68723 to 0.68721, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00070: val_loss did not improve from 0.68721\n","\n","Epoch 00071: val_loss did not improve from 0.68721\n","\n","Epoch 00072: val_loss improved from 0.68721 to 0.68693, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00073: val_loss did not improve from 0.68693\n","\n","Epoch 00074: val_loss did not improve from 0.68693\n","\n","Epoch 00075: val_loss did not improve from 0.68693\n","\n","Epoch 00076: val_loss did not improve from 0.68693\n","\n","Epoch 00077: val_loss did not improve from 0.68693\n","\n","Epoch 00078: val_loss did not improve from 0.68693\n","\n","Epoch 00079: val_loss did not improve from 0.68693\n","\n","Epoch 00080: val_loss did not improve from 0.68693\n","\n","Epoch 00081: val_loss did not improve from 0.68693\n","\n","Epoch 00082: val_loss improved from 0.68693 to 0.68681, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00083: val_loss did not improve from 0.68681\n","\n","Epoch 00084: val_loss did not improve from 0.68681\n","\n","Epoch 00085: val_loss did not improve from 0.68681\n","\n","Epoch 00086: val_loss did not improve from 0.68681\n","\n","Epoch 00087: val_loss did not improve from 0.68681\n","\n","Epoch 00088: val_loss did not improve from 0.68681\n","\n","Epoch 00089: val_loss did not improve from 0.68681\n","\n","Epoch 00090: val_loss did not improve from 0.68681\n","\n","Epoch 00091: val_loss did not improve from 0.68681\n","\n","Epoch 00092: val_loss did not improve from 0.68681\n","\n","Epoch 00093: val_loss did not improve from 0.68681\n","\n","Epoch 00094: val_loss did not improve from 0.68681\n","\n","Epoch 00095: val_loss did not improve from 0.68681\n","\n","Epoch 00096: val_loss improved from 0.68681 to 0.68659, saving model to /content/drive/My Drive/colab/46perror_weights_v9.h5\n","\n","Epoch 00097: val_loss did not improve from 0.68659\n","\n","Epoch 00098: val_loss did not improve from 0.68659\n","\n","Epoch 00099: val_loss did not improve from 0.68659\n","\n","Epoch 00100: val_loss did not improve from 0.68659\n","1253/1253 [==============================] - 0s 59us/sample - loss: 0.6865 - acc: 0.5587\n","[0.686545511340486, 0.5586592]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WlFuqjF2cLte","executionInfo":{"status":"ok","timestamp":1618981943696,"user_tz":420,"elapsed":18092939,"user":{"displayName":"Kate Groschner","photoUrl":"","userId":"03462860494048042586"}},"outputId":"1debcb63-acc8-4883-a013-d53b211b72a9"},"source":["wrong_frac = 0.48\n","version = 9\n","name_frac = str(wrong_frac).split('.')[-1]\n","if len(name_frac) == 1:\n","    name_frac = name_frac + '0'\n","if len(name_frac) == 1:\n","    name_frac = name_frac + '0'\n","save_weights = '/content/drive/My Drive/colab/'+ name_frac +'perror_weights_v'+ str(version) + '.h5'\n","save_history = '/content/drive/My Drive/colab/'+ name_frac +'perror_history_v'+ str(version) + '.h5'\n","\n","\n","seven_imgs_train = []\n","seven_labels_train = []\n","for idx,label in enumerate(data[0][1]):\n","    if label == 7:\n","        seven_imgs_train.append(data[0][0][idx])\n","        seven_labels_train.append(label)\n","seven_imgs_train = np.array(seven_imgs_train)\n","seven_labels_train = np.array(seven_labels_train)\n","\n","\n","new_left_images = []\n","new_left_labels = []\n","new_right_images = []\n","new_right_labels = []\n","\n","for img in seven_imgs_train:\n","    new_left_images.append(np.fliplr(img))\n","    new_left_labels.append(0)\n","    new_right_images.append(img)\n","    new_right_labels.append(1)\n","new_left_images = np.array(new_left_images)\n","new_right_images = np.array(new_right_images)\n","\n","split = int(seven_imgs_train.shape[0]*wrong_frac)\n","\n","for idx in np.arange(0,split):\n","    new_right_images[idx] = np.fliplr(new_right_images[idx])\n","\n","for idx in np.arange(0,split):\n","    new_left_images[idx] = np.fliplr(new_left_images[idx])\n","\n","\n","X = utils.shuffle(np.concatenate((new_right_images,new_left_images),axis =0),random_state=0)\n","Y = utils.shuffle(np.concatenate((new_right_labels,new_left_labels),axis = 0),random_state=0)\n","\n","train_split = int(len(X)*0.8)\n","val_split = train_split+int(len(X)*0.1)\n","\n","X_train = X[:train_split]\n","X_test = X[train_split:val_split]\n","# X_val = X[val_split:]\n","Y_train = Y[:train_split]\n","Y_test = Y[train_split:val_split]\n","# X_val = X[val_split:]\n","\n","X_train_norm = X_train/X_train.max()\n","X_test_norm = X_test/X_test.max()\n","X_train_norm = np.expand_dims(X_train_norm,axis=3)\n","X_test_norm = np.expand_dims(X_test_norm,axis=3)\n","\n","\n","batch_size = 32\n","seed = 42\n","\n","def random_180(img):\n","    turns = randint(0,2)\n","    turns  = turns*2\n","    return np.rot90(img,turns)\n","\n","train_datagen = ImageDataGenerator(\n","        rotation_range = 5,\n","        zoom_range=0.3,\n","        horizontal_flip=False,\n","        vertical_flip = False)\n","\n","test_datagen = ImageDataGenerator(\n","        rotation_range = 5,\n","        zoom_range=0.3,\n","        horizontal_flip=False,\n","        vertical_flip = False)\n","\n","\n","\n","train_generator = train_datagen.flow(X_train_norm, y=Y_train, batch_size=batch_size,seed=seed)\n","val_generator = test_datagen.flow(X_test_norm,y=Y_test,batch_size=batch_size,seed=seed)\n","\n","\n","modelE = keras.models.Sequential()\n","modelE.add(Conv2D(64, (3, 3), input_shape=(28, 28,1)))\n","modelE.add(Activation('relu'))\n","modelE.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\n","modelE.add(Conv2D(64, (3, 3)))\n","modelE.add(Activation('relu'))\n","modelE.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","modelE.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n","modelE.add(Dense(64))\n","modelE.add(Activation('relu'))\n","modelE.add(Dropout(0.5))\n","modelE.add(Dense(1))\n","modelE.add(Activation('sigmoid'))\n","\n","modelE.compile(loss='binary_crossentropy',\n","              optimizer='Adadelta',\n","              metrics=['accuracy'])\n","\n","\n","modelCheckpoint = ModelCheckpoint(save_weights,\n","                                  monitor = 'val_loss',\n","                                  save_best_only = True,\n","                                  mode = 'min',\n","                                  verbose = 2,\n","                                  save_weights_only = True)\n","callbacks_list = [modelCheckpoint]\n","history = modelE.fit_generator(\n","        train_generator,\n","        steps_per_epoch=2870,\n","        epochs=100,\n","        validation_data=val_generator,\n","        validation_steps=358,\n","        verbose = 0,\n","        callbacks=callbacks_list)\n","modelE.save_weights(save_weights)\n","h = h5py.File(save_history,'w')\n","h_keys = history.history.keys()\n","for k in h_keys:\n","    h.create_dataset(k,data=history.history[k])\n","h.close()\n","\n","print(modelE.evaluate(X_test_norm,Y_test))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["\n","Epoch 00001: val_loss improved from inf to 0.69277, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00002: val_loss improved from 0.69277 to 0.69268, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00003: val_loss did not improve from 0.69268\n","\n","Epoch 00004: val_loss improved from 0.69268 to 0.69265, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00005: val_loss improved from 0.69265 to 0.69240, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00006: val_loss improved from 0.69240 to 0.69214, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00007: val_loss improved from 0.69214 to 0.69214, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00008: val_loss improved from 0.69214 to 0.69213, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00009: val_loss improved from 0.69213 to 0.69205, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00010: val_loss did not improve from 0.69205\n","\n","Epoch 00011: val_loss did not improve from 0.69205\n","\n","Epoch 00012: val_loss improved from 0.69205 to 0.69193, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00013: val_loss did not improve from 0.69193\n","\n","Epoch 00014: val_loss did not improve from 0.69193\n","\n","Epoch 00015: val_loss improved from 0.69193 to 0.69185, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00016: val_loss improved from 0.69185 to 0.69172, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00017: val_loss improved from 0.69172 to 0.69157, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00018: val_loss improved from 0.69157 to 0.69148, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00019: val_loss did not improve from 0.69148\n","\n","Epoch 00020: val_loss did not improve from 0.69148\n","\n","Epoch 00021: val_loss did not improve from 0.69148\n","\n","Epoch 00022: val_loss did not improve from 0.69148\n","\n","Epoch 00023: val_loss improved from 0.69148 to 0.69134, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00024: val_loss did not improve from 0.69134\n","\n","Epoch 00025: val_loss did not improve from 0.69134\n","\n","Epoch 00026: val_loss improved from 0.69134 to 0.69115, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00027: val_loss improved from 0.69115 to 0.69109, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00028: val_loss did not improve from 0.69109\n","\n","Epoch 00029: val_loss did not improve from 0.69109\n","\n","Epoch 00030: val_loss improved from 0.69109 to 0.69093, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00031: val_loss did not improve from 0.69093\n","\n","Epoch 00032: val_loss improved from 0.69093 to 0.69074, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00033: val_loss did not improve from 0.69074\n","\n","Epoch 00034: val_loss did not improve from 0.69074\n","\n","Epoch 00035: val_loss did not improve from 0.69074\n","\n","Epoch 00036: val_loss did not improve from 0.69074\n","\n","Epoch 00037: val_loss did not improve from 0.69074\n","\n","Epoch 00038: val_loss did not improve from 0.69074\n","\n","Epoch 00039: val_loss did not improve from 0.69074\n","\n","Epoch 00040: val_loss did not improve from 0.69074\n","\n","Epoch 00041: val_loss did not improve from 0.69074\n","\n","Epoch 00042: val_loss did not improve from 0.69074\n","\n","Epoch 00043: val_loss did not improve from 0.69074\n","\n","Epoch 00044: val_loss improved from 0.69074 to 0.69068, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00045: val_loss improved from 0.69068 to 0.69064, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00046: val_loss improved from 0.69064 to 0.69040, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00047: val_loss did not improve from 0.69040\n","\n","Epoch 00048: val_loss did not improve from 0.69040\n","\n","Epoch 00049: val_loss improved from 0.69040 to 0.69036, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00050: val_loss did not improve from 0.69036\n","\n","Epoch 00051: val_loss did not improve from 0.69036\n","\n","Epoch 00052: val_loss did not improve from 0.69036\n","\n","Epoch 00053: val_loss did not improve from 0.69036\n","\n","Epoch 00054: val_loss did not improve from 0.69036\n","\n","Epoch 00055: val_loss did not improve from 0.69036\n","\n","Epoch 00056: val_loss did not improve from 0.69036\n","\n","Epoch 00057: val_loss did not improve from 0.69036\n","\n","Epoch 00058: val_loss did not improve from 0.69036\n","\n","Epoch 00059: val_loss improved from 0.69036 to 0.69029, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00060: val_loss did not improve from 0.69029\n","\n","Epoch 00061: val_loss improved from 0.69029 to 0.69014, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00062: val_loss did not improve from 0.69014\n","\n","Epoch 00063: val_loss did not improve from 0.69014\n","\n","Epoch 00064: val_loss did not improve from 0.69014\n","\n","Epoch 00065: val_loss did not improve from 0.69014\n","\n","Epoch 00066: val_loss did not improve from 0.69014\n","\n","Epoch 00067: val_loss did not improve from 0.69014\n","\n","Epoch 00068: val_loss did not improve from 0.69014\n","\n","Epoch 00069: val_loss did not improve from 0.69014\n","\n","Epoch 00070: val_loss improved from 0.69014 to 0.68980, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00071: val_loss did not improve from 0.68980\n","\n","Epoch 00072: val_loss did not improve from 0.68980\n","\n","Epoch 00073: val_loss did not improve from 0.68980\n","\n","Epoch 00074: val_loss did not improve from 0.68980\n","\n","Epoch 00075: val_loss did not improve from 0.68980\n","\n","Epoch 00076: val_loss did not improve from 0.68980\n","\n","Epoch 00077: val_loss did not improve from 0.68980\n","\n","Epoch 00078: val_loss did not improve from 0.68980\n","\n","Epoch 00079: val_loss improved from 0.68980 to 0.68979, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00080: val_loss improved from 0.68979 to 0.68969, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00081: val_loss did not improve from 0.68969\n","\n","Epoch 00082: val_loss did not improve from 0.68969\n","\n","Epoch 00083: val_loss did not improve from 0.68969\n","\n","Epoch 00084: val_loss did not improve from 0.68969\n","\n","Epoch 00085: val_loss did not improve from 0.68969\n","\n","Epoch 00086: val_loss did not improve from 0.68969\n","\n","Epoch 00087: val_loss did not improve from 0.68969\n","\n","Epoch 00088: val_loss did not improve from 0.68969\n","\n","Epoch 00089: val_loss improved from 0.68969 to 0.68964, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00090: val_loss did not improve from 0.68964\n","\n","Epoch 00091: val_loss did not improve from 0.68964\n","\n","Epoch 00092: val_loss did not improve from 0.68964\n","\n","Epoch 00093: val_loss did not improve from 0.68964\n","\n","Epoch 00094: val_loss did not improve from 0.68964\n","\n","Epoch 00095: val_loss did not improve from 0.68964\n","\n","Epoch 00096: val_loss improved from 0.68964 to 0.68905, saving model to /content/drive/My Drive/colab/48perror_weights_v9.h5\n","\n","Epoch 00097: val_loss did not improve from 0.68905\n","\n","Epoch 00098: val_loss did not improve from 0.68905\n","\n","Epoch 00099: val_loss did not improve from 0.68905\n","\n","Epoch 00100: val_loss did not improve from 0.68905\n","1253/1253 [==============================] - 0s 59us/sample - loss: 0.6890 - acc: 0.5435\n","[0.6890417766019238, 0.5434956]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZqX2-P_vtvQ0","executionInfo":{"status":"ok","timestamp":1618984546544,"user_tz":420,"elapsed":20695785,"user":{"displayName":"Kate Groschner","photoUrl":"","userId":"03462860494048042586"}},"outputId":"2bde9ac9-393b-4c58-e6bb-fccdb6655930"},"source":["wrong_frac = 0.5\n","version = 9\n","name_frac = str(wrong_frac).split('.')[-1]\n","if len(name_frac) == 1:\n","    name_frac = name_frac + '0'\n","if len(name_frac) == 1:\n","    name_frac = name_frac + '0'\n","save_weights = '/content/drive/My Drive/colab/'+ name_frac +'perror_weights_v'+ str(version) + '.h5'\n","save_history = '/content/drive/My Drive/colab/'+ name_frac +'perror_history_v'+ str(version) + '.h5'\n","\n","\n","seven_imgs_train = []\n","seven_labels_train = []\n","for idx,label in enumerate(data[0][1]):\n","    if label == 7:\n","        seven_imgs_train.append(data[0][0][idx])\n","        seven_labels_train.append(label)\n","seven_imgs_train = np.array(seven_imgs_train)\n","seven_labels_train = np.array(seven_labels_train)\n","\n","\n","new_left_images = []\n","new_left_labels = []\n","new_right_images = []\n","new_right_labels = []\n","\n","for img in seven_imgs_train:\n","    new_left_images.append(np.fliplr(img))\n","    new_left_labels.append(0)\n","    new_right_images.append(img)\n","    new_right_labels.append(1)\n","new_left_images = np.array(new_left_images)\n","new_right_images = np.array(new_right_images)\n","\n","split = int(seven_imgs_train.shape[0]*wrong_frac)\n","\n","for idx in np.arange(0,split):\n","    new_right_images[idx] = np.fliplr(new_right_images[idx])\n","\n","for idx in np.arange(0,split):\n","    new_left_images[idx] = np.fliplr(new_left_images[idx])\n","\n","\n","X = utils.shuffle(np.concatenate((new_right_images,new_left_images),axis =0),random_state=0)\n","Y = utils.shuffle(np.concatenate((new_right_labels,new_left_labels),axis = 0),random_state=0)\n","\n","train_split = int(len(X)*0.8)\n","val_split = train_split+int(len(X)*0.1)\n","\n","X_train = X[:train_split]\n","X_test = X[train_split:val_split]\n","# X_val = X[val_split:]\n","Y_train = Y[:train_split]\n","Y_test = Y[train_split:val_split]\n","# X_val = X[val_split:]\n","\n","X_train_norm = X_train/X_train.max()\n","X_test_norm = X_test/X_test.max()\n","X_train_norm = np.expand_dims(X_train_norm,axis=3)\n","X_test_norm = np.expand_dims(X_test_norm,axis=3)\n","\n","\n","batch_size = 32\n","seed = 42\n","\n","def random_180(img):\n","    turns = randint(0,2)\n","    turns  = turns*2\n","    return np.rot90(img,turns)\n","\n","train_datagen = ImageDataGenerator(\n","        rotation_range = 5,\n","        zoom_range=0.3,\n","        horizontal_flip=False,\n","        vertical_flip = False)\n","\n","test_datagen = ImageDataGenerator(\n","        rotation_range = 5,\n","        zoom_range=0.3,\n","        horizontal_flip=False,\n","        vertical_flip = False)\n","\n","\n","\n","train_generator = train_datagen.flow(X_train_norm, y=Y_train, batch_size=batch_size,seed=seed)\n","val_generator = test_datagen.flow(X_test_norm,y=Y_test,batch_size=batch_size,seed=seed)\n","\n","\n","modelE = keras.models.Sequential()\n","modelE.add(Conv2D(64, (3, 3), input_shape=(28, 28,1)))\n","modelE.add(Activation('relu'))\n","modelE.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","\n","modelE.add(Conv2D(64, (3, 3)))\n","modelE.add(Activation('relu'))\n","modelE.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","modelE.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n","modelE.add(Dense(64))\n","modelE.add(Activation('relu'))\n","modelE.add(Dropout(0.5))\n","modelE.add(Dense(1))\n","modelE.add(Activation('sigmoid'))\n","\n","modelE.compile(loss='binary_crossentropy',\n","              optimizer='Adadelta',\n","              metrics=['accuracy'])\n","\n","\n","modelCheckpoint = ModelCheckpoint(save_weights,\n","                                  monitor = 'val_loss',\n","                                  save_best_only = True,\n","                                  mode = 'min',\n","                                  verbose = 2,\n","                                  save_weights_only = True)\n","callbacks_list = [modelCheckpoint]\n","history = modelE.fit_generator(\n","        train_generator,\n","        steps_per_epoch=2870,\n","        epochs=100,\n","        validation_data=val_generator,\n","        validation_steps=358,\n","        verbose = 0,\n","        callbacks=callbacks_list)\n","modelE.save_weights(save_weights)\n","h = h5py.File(save_history,'w')\n","h_keys = history.history.keys()\n","for k in h_keys:\n","    h.create_dataset(k,data=history.history[k])\n","h.close()\n","\n","print(modelE.evaluate(X_test_norm,Y_test))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["\n","Epoch 00001: val_loss improved from inf to 0.69340, saving model to /content/drive/My Drive/colab/50perror_weights_v9.h5\n","\n","Epoch 00002: val_loss improved from 0.69340 to 0.69337, saving model to /content/drive/My Drive/colab/50perror_weights_v9.h5\n","\n","Epoch 00003: val_loss improved from 0.69337 to 0.69326, saving model to /content/drive/My Drive/colab/50perror_weights_v9.h5\n","\n","Epoch 00004: val_loss did not improve from 0.69326\n","\n","Epoch 00005: val_loss improved from 0.69326 to 0.69314, saving model to /content/drive/My Drive/colab/50perror_weights_v9.h5\n","\n","Epoch 00006: val_loss did not improve from 0.69314\n","\n","Epoch 00007: val_loss improved from 0.69314 to 0.69310, saving model to /content/drive/My Drive/colab/50perror_weights_v9.h5\n","\n","Epoch 00008: val_loss did not improve from 0.69310\n","\n","Epoch 00009: val_loss did not improve from 0.69310\n","\n","Epoch 00010: val_loss improved from 0.69310 to 0.69305, saving model to /content/drive/My Drive/colab/50perror_weights_v9.h5\n","\n","Epoch 00011: val_loss did not improve from 0.69305\n","\n","Epoch 00012: val_loss did not improve from 0.69305\n","\n","Epoch 00013: val_loss did not improve from 0.69305\n","\n","Epoch 00014: val_loss improved from 0.69305 to 0.69300, saving model to /content/drive/My Drive/colab/50perror_weights_v9.h5\n","\n","Epoch 00015: val_loss did not improve from 0.69300\n","\n","Epoch 00016: val_loss did not improve from 0.69300\n","\n","Epoch 00017: val_loss did not improve from 0.69300\n","\n","Epoch 00018: val_loss did not improve from 0.69300\n","\n","Epoch 00019: val_loss did not improve from 0.69300\n","\n","Epoch 00020: val_loss did not improve from 0.69300\n","\n","Epoch 00021: val_loss did not improve from 0.69300\n","\n","Epoch 00022: val_loss did not improve from 0.69300\n","\n","Epoch 00023: val_loss did not improve from 0.69300\n","\n","Epoch 00024: val_loss improved from 0.69300 to 0.69286, saving model to /content/drive/My Drive/colab/50perror_weights_v9.h5\n","\n","Epoch 00025: val_loss did not improve from 0.69286\n","\n","Epoch 00026: val_loss did not improve from 0.69286\n","\n","Epoch 00027: val_loss improved from 0.69286 to 0.69284, saving model to /content/drive/My Drive/colab/50perror_weights_v9.h5\n","\n","Epoch 00028: val_loss did not improve from 0.69284\n","\n","Epoch 00029: val_loss improved from 0.69284 to 0.69276, saving model to /content/drive/My Drive/colab/50perror_weights_v9.h5\n","\n","Epoch 00030: val_loss did not improve from 0.69276\n","\n","Epoch 00031: val_loss did not improve from 0.69276\n","\n","Epoch 00032: val_loss improved from 0.69276 to 0.69271, saving model to /content/drive/My Drive/colab/50perror_weights_v9.h5\n","\n","Epoch 00033: val_loss did not improve from 0.69271\n","\n","Epoch 00034: val_loss did not improve from 0.69271\n","\n","Epoch 00035: val_loss did not improve from 0.69271\n","\n","Epoch 00036: val_loss did not improve from 0.69271\n","\n","Epoch 00037: val_loss did not improve from 0.69271\n","\n","Epoch 00038: val_loss did not improve from 0.69271\n","\n","Epoch 00039: val_loss improved from 0.69271 to 0.69262, saving model to /content/drive/My Drive/colab/50perror_weights_v9.h5\n","\n","Epoch 00040: val_loss did not improve from 0.69262\n","\n","Epoch 00041: val_loss did not improve from 0.69262\n","\n","Epoch 00042: val_loss did not improve from 0.69262\n","\n","Epoch 00043: val_loss did not improve from 0.69262\n","\n","Epoch 00044: val_loss did not improve from 0.69262\n","\n","Epoch 00045: val_loss did not improve from 0.69262\n","\n","Epoch 00046: val_loss did not improve from 0.69262\n","\n","Epoch 00047: val_loss did not improve from 0.69262\n","\n","Epoch 00048: val_loss did not improve from 0.69262\n","\n","Epoch 00049: val_loss did not improve from 0.69262\n","\n","Epoch 00050: val_loss did not improve from 0.69262\n","\n","Epoch 00051: val_loss did not improve from 0.69262\n","\n","Epoch 00052: val_loss did not improve from 0.69262\n","\n","Epoch 00053: val_loss did not improve from 0.69262\n","\n","Epoch 00054: val_loss improved from 0.69262 to 0.69253, saving model to /content/drive/My Drive/colab/50perror_weights_v9.h5\n","\n","Epoch 00055: val_loss did not improve from 0.69253\n","\n","Epoch 00056: val_loss did not improve from 0.69253\n","\n","Epoch 00057: val_loss did not improve from 0.69253\n","\n","Epoch 00058: val_loss did not improve from 0.69253\n","\n","Epoch 00059: val_loss did not improve from 0.69253\n","\n","Epoch 00060: val_loss improved from 0.69253 to 0.69245, saving model to /content/drive/My Drive/colab/50perror_weights_v9.h5\n","\n","Epoch 00061: val_loss improved from 0.69245 to 0.69223, saving model to /content/drive/My Drive/colab/50perror_weights_v9.h5\n","\n","Epoch 00062: val_loss did not improve from 0.69223\n","\n","Epoch 00063: val_loss did not improve from 0.69223\n","\n","Epoch 00064: val_loss did not improve from 0.69223\n","\n","Epoch 00065: val_loss did not improve from 0.69223\n","\n","Epoch 00066: val_loss did not improve from 0.69223\n","\n","Epoch 00067: val_loss did not improve from 0.69223\n","\n","Epoch 00068: val_loss did not improve from 0.69223\n","\n","Epoch 00069: val_loss did not improve from 0.69223\n","\n","Epoch 00070: val_loss did not improve from 0.69223\n","\n","Epoch 00071: val_loss improved from 0.69223 to 0.69219, saving model to /content/drive/My Drive/colab/50perror_weights_v9.h5\n","\n","Epoch 00072: val_loss did not improve from 0.69219\n","\n","Epoch 00073: val_loss did not improve from 0.69219\n","\n","Epoch 00074: val_loss improved from 0.69219 to 0.69211, saving model to /content/drive/My Drive/colab/50perror_weights_v9.h5\n","\n","Epoch 00075: val_loss did not improve from 0.69211\n","\n","Epoch 00076: val_loss did not improve from 0.69211\n","\n","Epoch 00077: val_loss did not improve from 0.69211\n","\n","Epoch 00078: val_loss did not improve from 0.69211\n","\n","Epoch 00079: val_loss did not improve from 0.69211\n","\n","Epoch 00080: val_loss did not improve from 0.69211\n","\n","Epoch 00081: val_loss did not improve from 0.69211\n","\n","Epoch 00082: val_loss did not improve from 0.69211\n","\n","Epoch 00083: val_loss did not improve from 0.69211\n","\n","Epoch 00084: val_loss did not improve from 0.69211\n","\n","Epoch 00085: val_loss did not improve from 0.69211\n","\n","Epoch 00086: val_loss did not improve from 0.69211\n","\n","Epoch 00087: val_loss did not improve from 0.69211\n","\n","Epoch 00088: val_loss did not improve from 0.69211\n","\n","Epoch 00089: val_loss did not improve from 0.69211\n","\n","Epoch 00090: val_loss did not improve from 0.69211\n","\n","Epoch 00091: val_loss did not improve from 0.69211\n","\n","Epoch 00092: val_loss did not improve from 0.69211\n","\n","Epoch 00093: val_loss did not improve from 0.69211\n","\n","Epoch 00094: val_loss did not improve from 0.69211\n","\n","Epoch 00095: val_loss did not improve from 0.69211\n","\n","Epoch 00096: val_loss improved from 0.69211 to 0.69189, saving model to /content/drive/My Drive/colab/50perror_weights_v9.h5\n","\n","Epoch 00097: val_loss improved from 0.69189 to 0.69177, saving model to /content/drive/My Drive/colab/50perror_weights_v9.h5\n","\n","Epoch 00098: val_loss did not improve from 0.69177\n","\n","Epoch 00099: val_loss did not improve from 0.69177\n","\n","Epoch 00100: val_loss did not improve from 0.69177\n","1253/1253 [==============================] - 0s 60us/sample - loss: 0.6913 - acc: 0.5196\n","[0.6913051923940587, 0.51955307]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qPtya3FExYjD"},"source":[""],"execution_count":null,"outputs":[]}]}